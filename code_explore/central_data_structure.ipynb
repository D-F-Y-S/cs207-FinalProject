{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file contains the central data structure and functions related to the\n",
    "forward mode auto differentiation. We may want to separate the code into \n",
    "multiple files later.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Expression:\n",
    "    def __init__(self, ele_func, sub_expr1, sub_expr2=None):\n",
    "        self._ele_func  = ele_func\n",
    "        self._sub_expr1 = sub_expr1\n",
    "        self._sub_expr2 = sub_expr2\n",
    "    \n",
    "    def evaluation_at(self, val_dict):\n",
    "        \n",
    "        # self._sub_expr2 is None implies that self._ele_func is an unary operator\n",
    "        if self._sub_expr2 is None: \n",
    "            return self._ele_func.evaluation_at(\n",
    "                self._sub_expr1, val_dict)\n",
    "        \n",
    "        # self._sub_expr2 not None implies that self._ele_func is a binary operator\n",
    "        else:\n",
    "            return self._ele_func.evaluation_at(\n",
    "                self._sub_expr1, self._sub_expr2, val_dict)\n",
    "    \n",
    "    def derivative_at(self, var, val_dict, order=1):\n",
    "        \n",
    "        # var being a tuple implies multivariate higher derivatives\n",
    "#        if type(var) is tuple:\n",
    "#            if len(var) != 2:\n",
    "#                raise NotImplementedError('only 2nd order derivatives implemented for multivariate derivatives')\n",
    "#            var1, var2 = var\n",
    "#            # sub_expr2 being None implies that _ele_func is an unary operator\n",
    "#            if self._sub_expr2 is None:\n",
    "#                return self._ele_func.derivative_at(\n",
    "#                    self._sub_expr1, var, val_dict, order) \n",
    "#            # sub_expr2 not None implies that _ele_func is a binary operator\n",
    "#            else:\n",
    "#                return self._ele_func.derivative_at(\n",
    "#                    self._sub_expr1, self._sub_expr2, var, val_dict, order)\n",
    "\n",
    "        if var is self: \n",
    "            if   order == 1: return 1.0\n",
    "            else: return 0.0\n",
    "        \n",
    "        # sub_expr2 being None implies that _ele_func is an unary operator\n",
    "        if self._sub_expr2 is None:\n",
    "            return self._ele_func.derivative_at(\n",
    "                self._sub_expr1, var, val_dict, order)\n",
    "        \n",
    "        # sub_expr2 not None implies that _ele_func is a binary operator\n",
    "        else:\n",
    "            return self._ele_func.derivative_at(\n",
    "                self._sub_expr1, self._sub_expr2, var, val_dict, order)\n",
    "    \n",
    "    def gradient_at(self, val_dict, returns_dict=False):\n",
    "        if returns_dict:\n",
    "            return {v: self.derivative_at(v, val_dict) for v in val_dict.keys()}\n",
    "        return np.array([self.derivative_at(var, val_dict, order=1) \n",
    "                         for var in val_dict.keys()])\n",
    "    \n",
    "    def hessian_at(self, val_dict):\n",
    "        return np.array( [ \\\n",
    "                          [self.derivative_at((var1, var2), val_dict, order=2)\n",
    "                           for var1 in val_dict.keys()]\n",
    "                          for var2 in val_dict.keys() \\\n",
    "                          ] )\n",
    "    \n",
    "    def __neg__(self):\n",
    "        return Expression(Neg, self)\n",
    "\n",
    "                \n",
    "    def __add__(self, another):\n",
    "        if isinstance(another, Expression):\n",
    "            return Expression(Add, self, another)\n",
    "        # if the other operand is not an Expression, then it must be a number\n",
    "        # the number then should be converted to a Constant\n",
    "        else:\n",
    "            return Expression(Add, self, Constant(another))\n",
    "    \n",
    "    \n",
    "    def __radd__(self, another):\n",
    "        if isinstance(another, Expression):\n",
    "            return Expression(Add, another, self)\n",
    "        else:\n",
    "            return Expression(Add, Constant(another), self)\n",
    "    \n",
    "    def __sub__(self, another):\n",
    "        if isinstance(another, Expression):\n",
    "            return Expression(Sub, self, another)\n",
    "        else:\n",
    "            return Expression(Sub, self, Constant(another))\n",
    "    \n",
    "    def __rsub__(self, another):\n",
    "        if isinstance(another, Expression):\n",
    "            return Expression(Sub, another, self)\n",
    "        else:\n",
    "            return Expression(Sub, Constant(another), self)\n",
    "        \n",
    "\n",
    "    def __mul__(self, another):\n",
    "        if isinstance(another, Expression):\n",
    "            return Expression(Mul,self,another)\n",
    "        else:\n",
    "            return Expression(Mul, self, Constant(another))\n",
    "\n",
    "    def __rmul__(self, another):\n",
    "        if isinstance(another, Expression):\n",
    "            return Expression(Mul,another,self)\n",
    "        else:\n",
    "            return Expression(Mul, Constant(another),self)\n",
    "    \n",
    "    def __truediv__(self, another):\n",
    "        if isinstance(another, Expression):\n",
    "            return Expression(Div,self,another)\n",
    "        else:\n",
    "            return Expression(Div, self, Constant(another))\n",
    "\n",
    "    def __rtruediv__(self, another):\n",
    "        if isinstance(another, Expression):\n",
    "            return Expression(Div,another,self)\n",
    "        else:\n",
    "            return Expression(Div, Constant(another),self)\n",
    "    \n",
    "    def __pow__(self,another):\n",
    "        if isinstance(another, Expression):\n",
    "            return Expression(Pow,self,another)\n",
    "        else:\n",
    "            return Expression(Pow, self, Constant(another))\n",
    "    \n",
    "    def __rpow__(self,another):\n",
    "        if isinstance(another, Expression):\n",
    "            return Expression(Pow,another,self)\n",
    "        else:\n",
    "            return Expression(Pow, Constant(another),self)\n",
    "\n",
    "\n",
    "class Variable(Expression):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def evaluation_at(self, val_dict):\n",
    "        return val_dict[self]\n",
    "    \n",
    "    def derivative_at(self, var, val_dict, order=1):\n",
    "        if order == 1:\n",
    "            return 1.0 if var is self else 0.0\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "\n",
    "class Constant(Expression):\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "        \n",
    "    def evaluation_at(self, val_dict):\n",
    "        return self.val\n",
    "    \n",
    "    def derivative_at(self, var, val_dict, order=1):\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "class VectorFunction:\n",
    "    \n",
    "    def __init__(self, exprlist):\n",
    "        self._exprlist = exprlist.copy()\n",
    "    \n",
    "    def evaluation_at(self, val_dict):\n",
    "        return np.array([expr.evaluation_at(val_dict) \n",
    "                        for expr in self._exprlist])\n",
    "    \n",
    "    def gradient_at(self, var, val_dict):\n",
    "        return np.array([f.derivative_at(var, val_dict) for f in self._exprlist])\n",
    "    \n",
    "    def jacobian_at(self, val_dict):\n",
    "        return np.array([self.gradient_at(var, val_dict)\n",
    "                         for var in val_dict.keys()]).transpose()\n",
    "\n",
    "\n",
    "class Add:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1, sub_expr2, val_dict):\n",
    "        return sub_expr1.evaluation_at(val_dict) + \\\n",
    "               sub_expr2.evaluation_at(val_dict)\n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1, sub_expr2, var, val_dict, order=1):\n",
    "        return sub_expr1.derivative_at(var, val_dict, order) + \\\n",
    "               sub_expr2.derivative_at(var, val_dict, order)\n",
    "\n",
    "class Sub:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1, sub_expr2, val_dict):\n",
    "        return sub_expr1.evaluation_at(val_dict) - \\\n",
    "               sub_expr2.evaluation_at(val_dict)\n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1, sub_expr2, var, val_dict, order=1):\n",
    "        return sub_expr1.derivative_at(var, val_dict, order) - \\\n",
    "               sub_expr2.derivative_at(var, val_dict, order)\n",
    "\n",
    "class Mul:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1, sub_expr2, val_dict):\n",
    "        return sub_expr1.evaluation_at(val_dict) *\\\n",
    "               sub_expr2.evaluation_at(val_dict)\n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1, sub_expr2, var, val_dict,order=1):\n",
    "        if   order == 1:\n",
    "            return sub_expr1.derivative_at(var, val_dict) * \\\n",
    "                   sub_expr2.evaluation_at(val_dict)+ \\\n",
    "                   sub_expr1.evaluation_at(val_dict) *\\\n",
    "                   sub_expr2.derivative_at(var, val_dict)\n",
    "        elif order == 2:\n",
    "            if type(var) is tuple:\n",
    "                var1, var2 = var\n",
    "                term1 = sub_expr1.derivative_at(var, val_dict, order=2) \\\n",
    "                        * sub_expr2.evaluation_at(val_dict)\n",
    "                term2 = sub_expr2.derivative_at(var, val_dict, order=2) \\\n",
    "                        * sub_expr1.evaluation_at(val_dict)\n",
    "                term3 = sub_expr1.derivative_at(var1, val_dict, order=1) \\\n",
    "                        * sub_expr2.derivative_at(var2, val_dict, order=1)\n",
    "                term4 = sub_expr2.derivative_at(var1, val_dict, order=1) \\\n",
    "                        * sub_expr1.derivative_at(var2, val_dict, order=1)\n",
    "                return term1 + term2 + term3 + term4\n",
    "            else:\n",
    "                return Mul.derivative_at(sub_expr1, sub_expr2, (var, var), val_dict, order=2)\n",
    "#            return sub_expr1.derivative_at(var, val_dict,2)*sub_expr2.evaluation_at(val_dict)+\\\n",
    "#                   sub_expr1.derivative_at(var, val_dict,1)*sub_expr2.derivative_at(var, val_dict,1)+\\\n",
    "#                   sub_expr1.derivative_at(var, val_dict,1)*sub_expr2.derivative_at(var, val_dict,1)+\\\n",
    "#                   sub_expr1.evaluation_at(val_dict)*sub_expr2.derivative_at(var, val_dict,2)\n",
    "        else: raise NotImplementedError('3rd order or higher derivatives are not implemented.')\n",
    "               \n",
    "class Div:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1, sub_expr2, val_dict):\n",
    "        return sub_expr1.evaluation_at(val_dict) /\\\n",
    "               sub_expr2.evaluation_at(val_dict)\n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1, sub_expr2, var, val_dict,order=1):\n",
    "        if   order == 1:\n",
    "            return  sub_expr1.derivative_at(var, val_dict) / \\\n",
    "                    sub_expr2.evaluation_at(val_dict)- \\\n",
    "                    sub_expr1.evaluation_at(val_dict) *\\\n",
    "                    sub_expr2.derivative_at(var, val_dict)/\\\n",
    "                    sub_expr2.evaluation_at(val_dict)**2\n",
    "        elif order == 2:\n",
    "            if type(var) is tuple:\n",
    "                var1, var2 = var\n",
    "                f = sub_expr1.evaluation_at(val_dict)\n",
    "                g = sub_expr2.evaluation_at(val_dict)\n",
    "                term1 =  1/g    * sub_expr2.derivative_at(var, val_dict, order=2)\n",
    "                term2 = -f/g**2 * sub_expr1.derivative_at(var, val_dict, order=2)\n",
    "                term3 = -1/g**2 * sub_expr1.derivative_at(var1, val_dict, order=1) \\\n",
    "                                * sub_expr2.derivative_at(var2, val_dict, order=1)\n",
    "                term4 = -1/g**2 * sub_expr1.derivative_at(var2, val_dict, order=1) \\\n",
    "                                * sub_expr2.derivative_at(var1, val_dict, order=1)\n",
    "                term5 = 2*f/g**3 * sub_expr2.derivative_at(var1, val_dict, order=1) \\\n",
    "                                 * sub_expr2.derivative_at(var2, val_dict, order=1)\n",
    "                return term1 + term2 + term3 + term4 + term5  \n",
    "            else:\n",
    "                return Div.derivative_at(sub_expr1, sub_expr2, (var, var), val_dict, order=2)\n",
    "#            return ((sub_expr1.derivative_at(var, val_dict,2)*\\\n",
    "#                    sub_expr2.evaluation_at(val_dict)-\\\n",
    "#                    sub_expr1.evaluation_at(val_dict)*\\\n",
    "#                    sub_expr2.derivative_at(var, val_dict,2))*sub_expr2.evaluation_at(val_dict)**2 -\\\n",
    "#                    2*(sub_expr1.derivative_at(var, val_dict,1)*\\\n",
    "#                    sub_expr2.evaluation_at(val_dict) -\\\n",
    "#                    sub_expr1.evaluation_at(val_dict)*\\\n",
    "#                    sub_expr2.derivative_at(var, val_dict,1))*\\\n",
    "#                    sub_expr2.evaluation_at(val_dict)*\\\n",
    "#                    sub_expr2.derivative_at(var, val_dict,1))/\\\n",
    "#                    sub_expr2.evaluation_at(val_dict)**4\n",
    "        else: raise NotImplementedError('3rd order or higher derivatives are not implemented.')\n",
    "\n",
    "#class Pow:\n",
    "#    \n",
    "#    @staticmethod\n",
    "#    def evaluation_at(sub_expr1, sub_expr2, val_dict):\n",
    "#        return sub_expr1.evaluation_at(val_dict) **\\\n",
    "#               sub_expr2.evaluation_at(val_dict)\n",
    "#    @staticmethod\n",
    "#    #f(x)^g(x) * g‘(x)  * ln( f(x) )+ f(x)^( g(x)-1 ) * g(x) * f’(x) \n",
    "#    def derivative_at(sub_expr1, sub_expr2, var, val_dict):\n",
    "#        return  sub_expr1.evaluation_at(val_dict)** \\\n",
    "#                sub_expr2.evaluation_at(val_dict)* \\\n",
    "#                sub_expr2.derivative_at(var, val_dict)*\\\n",
    "#                np.log(sub_expr1.evaluation_at(val_dict))+ \\\n",
    "#                sub_expr1.evaluation_at(val_dict) **\\\n",
    "#                (sub_expr2.evaluation_at(val_dict)-1)*\\\n",
    "#                sub_expr2.evaluation_at(val_dict)*\\\n",
    "#                sub_expr1.derivative_at(var, val_dict)\n",
    "\n",
    "# a simplified version: assuming sub_expr2 is a constant\n",
    "class Pow:\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1, sub_expr2, val_dict):\n",
    "        return np.power(sub_expr1.evaluation_at(val_dict), \n",
    "                        sub_expr2.evaluation_at(val_dict))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1, sub_expr2, var, val_dict,order=1):\n",
    "        p = sub_expr2.evaluation_at(val_dict)\n",
    "        if   order == 1:\n",
    "            return p*np.power(sub_expr1.evaluation_at(val_dict), p-1.0) \\\n",
    "                   * sub_expr1.derivative_at(var, val_dict)\n",
    "        elif order == 2:\n",
    "            if type(var) is tuple:\n",
    "                var1, var2 = var\n",
    "                term1 = p*np.power(sub_expr1.evaluation_at(val_dict), p-1.0) \\\n",
    "                        * sub_expr1.derivative_at((var1, var2), val_dict, order=2)\n",
    "                term2 = p*(p-1.0)*np.power(sub_expr1.evaluation_at(val_dict), p-2.0) \\\n",
    "                        * sub_expr1.derivative_at(var1, val_dict, order=1) \\\n",
    "                        * sub_expr1.derivative_at(var2, val_dict, order=1)\n",
    "                return term1 + term2\n",
    "            else:\n",
    "                return Pow.derivative_at(sub_expr1, sub_expr2, (var, var), val_dict, order=2)\n",
    "#            return p*(p-1)*np.power(sub_expr1.evaluation_at(val_dict),p-2.0)*sub_expr1.derivative_at(var, val_dict)**2\\\n",
    "#                    + p*np.power(sub_expr1.evaluation_at(val_dict), p-1.0)*sub_expr1.derivative_at(var, val_dict,2)\n",
    "        else: raise NotImplementedError('3rd order or higher derivatives are not implemented.')\n",
    "\n",
    "#def pow(expr1, expr2):\n",
    "#    return Expression(Pow, expr1, expr2)\n",
    "\n",
    "class Exp:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1, val_dict):\n",
    "        return np.exp(sub_expr1.evaluation_at(val_dict))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1, var, val_dict, order=1):\n",
    "        if   order == 1:\n",
    "            return sub_expr1.derivative_at(var, val_dict) * \\\n",
    "                   np.exp(sub_expr1.evaluation_at(val_dict))\n",
    "        elif order == 2:\n",
    "            if type(var) is tuple:\n",
    "                var1, var2 = var\n",
    "                f = sub_expr1.evaluation_at(val_dict)\n",
    "                term1 = np.exp(f) * sub_expr1.derivative_at(var,  val_dict, order=2)\n",
    "                term2 = np.exp(f) * sub_expr1.derivative_at(var1, val_dict, order=1) \\\n",
    "                                  * sub_expr1.derivative_at(var2, val_dict, order=1)\n",
    "                return term1 + term2\n",
    "            else:\n",
    "                return Exp.derivative_at(sub_expr1, (var,var), val_dict, order=2)\n",
    "#            return np.exp(sub_expr1.evaluation_at(val_dict)) * (sub_expr1.derivative_at(var, val_dict, order=1))**2 \\\n",
    "#                 + np.exp(sub_expr1.evaluation_at(val_dict)) *  sub_expr1.derivative_at(var, val_dict, order=2)\n",
    "        else: raise NotImplementedError('3rd order or higher derivatives are not implemented.')\n",
    "\n",
    "class Neg:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1, val_dict):\n",
    "        return -sub_expr1.evaluation_at(val_dict)\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1, var, val_dict, order=1):\n",
    "        return -sub_expr1.derivative_at(var, val_dict, order)\n",
    "\n",
    "def exp(expr):\n",
    "    return Expression(Exp, expr)\n",
    "\n",
    "\n",
    "class Sin:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1, val_dict):\n",
    "        return np.sin(sub_expr1.evaluation_at(val_dict))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1, var, val_dict, order=1):\n",
    "        if   order == 1:\n",
    "            return sub_expr1.derivative_at(var, val_dict, order) * \\\n",
    "            np.cos(sub_expr1.evaluation_at(val_dict))\n",
    "        elif order == 2:\n",
    "            if type(var) is tuple:\n",
    "                var1, var2 = var\n",
    "                f = sub_expr1.evaluation_at(val_dict)\n",
    "                term1 =  np.cos(f) * sub_expr1.derivative_at(var,  val_dict, order=2)\n",
    "                term2 = -np.sin(f) * sub_expr1.derivative_at(var1, val_dict, order=1) \\\n",
    "                                   * sub_expr1.derivative_at(var2, val_dict, order=1)\n",
    "                return term1 + term2\n",
    "            else:\n",
    "                return Sin.derivative_at(sub_expr1, (var,var), val_dict, order=2)\n",
    "#            return -np.sin(sub_expr1.evaluation_at(val_dict)) * \\\n",
    "#                   sub_expr1.derivative_at(var, val_dict, order=1)**2 + \\\n",
    "#                   np.cos(sub_expr1.evaluation_at(val_dict)) * \\\n",
    "#                   sub_expr1.derivative_at(var, val_dict, order=2)\n",
    "        else: raise NotImplementedError('3rd order or higher derivatives are not implemented.')\n",
    "\n",
    "def sin(expr):\n",
    "    return Expression(Sin, expr)\n",
    "\n",
    "class Cos:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        return np.cos(sub_expr1.evaluation_at(val_dict))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1):\n",
    "        if   order == 1:\n",
    "            return -sub_expr1.derivative_at(var, val_dict, order) * \\\n",
    "                   np.sin(sub_expr1.evaluation_at(val_dict)) \n",
    "        elif order == 2:\n",
    "            if type(var) is tuple:\n",
    "                var1, var2 = var\n",
    "                f = sub_expr1.evaluation_at(val_dict)\n",
    "                term1 = -np.sin(f) * sub_expr1.derivative_at(var,  val_dict, order=2)\n",
    "                term2 = -np.cos(f) * sub_expr1.derivative_at(var1, val_dict, order=1) \\\n",
    "                                   * sub_expr1.derivative_at(var2, val_dict, order=1)\n",
    "                return term1 + term2\n",
    "            else:\n",
    "                return Cos.derivative_at(sub_expr1, (var,var), val_dict, order=2)\n",
    "#            return -np.cos(sub_expr1.evaluation_at(val_dict)) * \\\n",
    "#                   sub_expr1.derivative_at(var, val_dict, order=1)**2 + \\\n",
    "#                   -np.sin(sub_expr1.evaluation_at(val_dict)) * \\\n",
    "#                   sub_expr1.derivative_at(var, val_dict, order=2)\n",
    "        else: raise NotImplementedError('3rd order or higher derivatives are not implemented.')\n",
    "\n",
    "def cos(expr):\n",
    "    return Expression(Cos, expr)\n",
    "    \n",
    "class Tan:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        return np.tan(sub_expr1.evaluation_at(val_dict))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1):\n",
    "        if   order == 1:\n",
    "            return sub_expr1.derivative_at(var, val_dict) * \\\n",
    "                   (1/np.cos(2*sub_expr1.evaluation_at(val_dict)))\n",
    "        elif order == 2:\n",
    "            if type(var) is tuple:\n",
    "                var1, var2 = var\n",
    "                f = sub_expr1.evaluation_at(val_dict)\n",
    "                term1 = 1/(np.cos(f)**2) * sub_expr1.derivative_at(var,  val_dict, order=2)\n",
    "                term2 = 2*np.tan(f)/(np.cos(f)**2) \\\n",
    "                        * sub_expr1.derivative_at(var1, val_dict, order=1) \\\n",
    "                        * sub_expr1.derivative_at(var2, val_dict, order=1)\n",
    "                return term1 + term2\n",
    "            else:\n",
    "                return Tan.derivative_at(sub_expr1, (var,var), val_dict, order=2)\n",
    "#            u = sub_expr1.evaluation_at(val_dict)\n",
    "#            return 2*np.tan(u)/(np.cos(u)**2) * (sub_expr1.derivative_at(var, val_dict))**2 \\\n",
    "#                           + 1/(np.cos(u)**2) *  sub_expr1.derivative_at(var, val_dict, order=2)\n",
    "        else: raise NotImplementedError('3rd order or higher derivatives are not implemented.')\n",
    "\n",
    "def tan(expr):\n",
    "    return Expression(Tan, expr)\n",
    "    \n",
    "class Cotan:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        return 1/np.tan(sub_expr1.evaluation_at(val_dict))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1): \n",
    "        if order == 1:\n",
    "            return -sub_expr1.derivative_at(var, val_dict) * \\\n",
    "                   (1/np.sin(sub_expr1.evaluation_at(val_dict))**2)\n",
    "        else: raise NotImplementedError('higher order derivatives not implemented for cotan.')\n",
    "            \n",
    "\n",
    "def cotan(expr):\n",
    "    return Expression(Cotan, expr)\n",
    "    \n",
    "class Sec:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        return 1/np.cos(sub_expr1.evaluation_at(val_dict))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        if order == 1:\n",
    "            return sub_expr1.derivative_at(var, val_dict) * \\\n",
    "                   np.tan(x) * (1/np.cos(x))\n",
    "        else: raise NotImplementedError('higher order derivatives not implemented for sec.')\n",
    "        \n",
    "def sec(expr):\n",
    "    return Expression(Sec, expr) \n",
    "\n",
    "class Csc:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        return 1/np.sin(sub_expr1.evaluation_at(val_dict))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        if order == 1:\n",
    "            return sub_expr1.derivative_at(var, val_dict) * \\\n",
    "                   (1/np.tan(x)) * (1/np.sin(x))\n",
    "        else: raise NotImplementedError('higher order derivatives not implemented for csc.')\n",
    "\n",
    "def csc(expr):\n",
    "    return Expression(Csc, expr) \n",
    "\n",
    "class Sinh:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        return np.sinh(sub_expr1.evaluation_at(val_dict))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        if order == 1:\n",
    "            return sub_expr1.derivative_at(var, val_dict) * np.cosh(x)\n",
    "        else: raise NotImplementedError('higher order derivatives not implemented for sinh.')\n",
    "\n",
    "def sinh(expr):\n",
    "    return Expression(Sinh, expr) \n",
    "\n",
    "class Cosh:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        return np.cosh(sub_expr1.evaluation_at(val_dict))\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        if order == 1:\n",
    "            return sub_expr1.derivative_at(var, val_dict) * np.sinh(x)\n",
    "        else: raise NotImplementedError('higher order derivatives not implemented for cosh.')\n",
    "\n",
    "def cosh(expr):\n",
    "    return Expression(Cosh, expr) \n",
    "    \n",
    "class Tanh:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        return np.sinh(x)/np.cosh(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        if order == 1:\n",
    "            return sub_expr1.derivative_at(var, val_dict) * (x/np.cosh(x)**2)\n",
    "        else: raise NotImplementedError('higher order derivatives not implemented for tanh.')\n",
    "\n",
    "def tanh(expr):\n",
    "    return Expression(Tanh,expr) \n",
    "\n",
    "class Csch:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        return 1/np.sinh(x)\n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        # d = -csch(x)*cot(x)\n",
    "        d = -(1/np.sinh(x)) * (np.cosh(x)/np.sinh(x))\n",
    "        if order == 1:\n",
    "            return sub_expr1.derivative_at(var, val_dict) * d\n",
    "        else: raise NotImplementedError('higher order derivatives not implemented for csch.')\n",
    "\n",
    "def csch(expr):\n",
    "    return Expression(Csch, expr) \n",
    "\n",
    "class Sech:\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        return 1/np.cosh(x)\n",
    "    \n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        # d = -sech(x)tanh(x)\n",
    "        d = -(1/np.cosh(x)) * (np.sinh(x)/np.cosh(x))\n",
    "        if order == 1:\n",
    "            return sub_expr1.derivative_at(var, val_dict)*d\n",
    "        else: raise NotImplementedError('higher order derivatives not implemented for sech.')\n",
    "\n",
    "def sech(expr):\n",
    "    return Expression(Sech, expr) \n",
    "\n",
    "class Coth:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        return np.cosh(x)/np.sinh(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        # d = -csch^2(x)\n",
    "        if order == 1:\n",
    "            return -sub_expr1.derivative_at(var, val_dict) * (1/np.sinh(x)**2)\n",
    "        else: raise NotImplementedError('higher order derivatives not implemented for cotan.')\n",
    "\n",
    "def coth(expr):\n",
    "    return Expression(Coth, expr)    \n",
    "\n",
    "class Arcsin:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        return np.arcsin(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        d = 1/np.sqrt(1-x**2)\n",
    "        #1/sqrt(1-x^2)\n",
    "        if order == 1:\n",
    "            return sub_expr1.derivative_at(var, val_dict) * d\n",
    "        else: raise NotImplementedError('higher order derivatives not implemented for arcsin.')\n",
    "\n",
    "def arcsin(expr):\n",
    "    return Expression(Arcsin, expr)\n",
    "    \n",
    "class Arccos:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        return np.arccos(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        d = 1/np.sqrt(1-x**2)\n",
    "        #-1/sqrt(1-x^2)\n",
    "        if order == 1:\n",
    "            return -sub_expr1.derivative_at(var, val_dict) * d\n",
    "        else: raise NotImplementedError('higher order derivatives not implemented for arccos.')\n",
    "\n",
    "def arccos(expr):\n",
    "    return Expression(Arccos, expr)\n",
    "    \n",
    "class Arctan:\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1,val_dict):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        return np.arctan(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1,var,val_dict, order=1):\n",
    "        x = sub_expr1.evaluation_at(val_dict)\n",
    "        d = 1/(1+x**2)\n",
    "        # d =1/1-x^2\n",
    "        if order == 1:\n",
    "            return sub_expr1.derivative_at(var, val_dict) * d\n",
    "        else: raise NotImplementedError('higher order derivatives not implemented for arctan.')\n",
    "\n",
    "def arctan(expr):\n",
    "    return Expression(Arctan, expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $f(a, b, c) = e^{a-b+c}$, at $(a, b, c) = (1.0, 2.0, 3.0)$, that should be $e^{2} \\approx 7.389$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x= Variable()\n",
    "y = Variable()\n",
    "f =x**3*y**3\n",
    "g=(x/y)**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\dfrac{\\partial f}{\\partial b} = -e^{a-b+c}$, at $(a, b, c) = (1.0, 2.0, 3.0)$, that should be $-e^{2} \\approx -7.389$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44444444444444442"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.derivative_at(x, val_dict={x:2,y:3},order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.derivative_at(y, val_dict={x:1,y:1},order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6*2/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(12*1**3)/(1**5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\dfrac{\\partial f}{\\partial a} = e^{a-b+c}$, at $(a, b) = (1.0, 2.0, 3.0)$, that should be $e^{2} \\approx 7.389$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-a84c688003dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderivative_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "f.derivative_at(a, {a: 1.0, b: 2.0, c: 3.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $g(x, y) = x + e^{y-1}$, at $(x, y) = (1.0, 2.0)$, that should be $1+e \\approx 3.718$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable()\n",
    "y = Variable()\n",
    "g = x + exp(y-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.evaluation_at({x: 1.0, y: 2.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\dfrac{\\partial g}{\\partial x} = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.derivative_at(x, {x: 1.0, y: 2.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\dfrac{\\partial g}{\\partial y} = e^{y-1}$, at $(x, y) = (1.0, 2.0)$, that should be $e^{1} \\approx 2.718$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.derivative_at(y, {x: 1.0, y: 2.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable()\n",
    "y = Variable()\n",
    "g = x*y\n",
    "f = x/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.evaluation_at({x: 2.0, y: 2.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.derivative_at(x, {x: 1.0, y: 2.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.evaluation_at({x: 3.0, y: 2.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.derivative_at(y, {x: 4.0, y: 2.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test for Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable()\n",
    "y = Variable()\n",
    "g = x**y\n",
    "f = x**2+x**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.evaluation_at({x: 3.0, y: 2.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.derivative_at(x, {x: 3.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5*3**(-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g.derivative_at(x, {x: 3.0, y: 2.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for unary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Variable()\n",
    "f= -x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.evaluation_at({x:2,y:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.derivative_at(x,2,{x:2,y:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import their package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def newton(f,  init_val_dict, max_iter=100, stop_stepsize=1e-8,return_history=False):\n",
    "    \n",
    "    variables  = [var for var in init_val_dict.keys()]\n",
    "    curr_point = np.array([v for k, v in init_val_dict.items()])\n",
    "    f_grad = f.gradient_at(init_val_dict)\n",
    "    f_hess = f.hessian_at(init_val_dict)\n",
    "    history = [curr_point.tolist()]\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        curr_val_dict = {var: val for var, val in zip(variables, curr_point)}\n",
    "        # solve (Hessian of f at x)s = - (gradient of f at x)\n",
    "        f_grad =f.gradient_at(curr_val_dict)\n",
    "        f_hess = f.hessian_at(curr_val_dict)\n",
    "\n",
    "        step = np.linalg.solve(f_hess, -f_grad)\n",
    "        if np.linalg.norm(step, ord=2) < stop_stepsize: break\n",
    "        \n",
    "        # x := x + s\n",
    "        curr_point = curr_point + step\n",
    "        history.append(curr_point.tolist())\n",
    "    \n",
    "    if return_history:\n",
    "        return history\n",
    "    \n",
    "    return {var: val for var, val in zip(variables, curr_point)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(f,init_val_dict, learning_rate=0.0001, max_iter=1000, stop_stepsize=0.000001,return_history=False):\n",
    "    f_grad = f.gradient_at(init_val_dict)\n",
    "    variables  = [var for var in init_val_dict.keys()]\n",
    "    curr_point = np.array([v for k, v in init_val_dict.items()])\n",
    "    history = [curr_point.tolist()]\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        prev_point =curr_point\n",
    "        prev_val_dict = {var: val for var, val in zip(variables, prev_point)}\n",
    "        f_grad =f.gradient_at(prev_val_dict)\n",
    "\n",
    "        curr_point =curr_point - learning_rate*f_grad\n",
    "        history.append(curr_point.tolist())\n",
    "        if np.linalg.norm(curr_point-prev_point, ord=2) < stop_stepsize: break\n",
    "        \n",
    "    if return_history:\n",
    "        return history\n",
    "    \n",
    "    return {var: val for var, val in zip(variables, curr_point)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, -1],\n",
       " [-0.9196, -0.96],\n",
       " [-0.85279652953856, -0.9238867168],\n",
       " [-0.7961022171169866, -0.8908637440481397],\n",
       " [-0.747192146195965, -0.8603708943652053],\n",
       " [-0.7044420342167079, -0.8319975544111625],\n",
       " [-0.6666745312441529, -0.8054328317315118],\n",
       " [-0.6330104628152412, -0.7804350764846893],\n",
       " [-0.6027769693956527, -0.7568123300343242],\n",
       " [-0.5754483311270671, -0.7344092819369616],\n",
       " [-0.5506064812245214, -0.7130982806622839],\n",
       " [-0.5279138589715093, -0.6927729651057092],\n",
       " [-0.5070942614424467, -0.6733436449537111],\n",
       " [-0.48791903281901494, -0.6547338802548797],\n",
       " [-0.47019690670606124, -0.6368779029980413],\n",
       " [-0.45376640473713054, -0.6197186423165615],\n",
       " [-0.4384900596395383, -0.603206190468869],\n",
       " [-0.4242499635826507, -0.5872965960114379],\n",
       " [-0.410944294577069, -0.5719509034592115],\n",
       " [-0.39848457508081503, -0.5571343811251184],\n",
       " [-0.3867934859458238, -0.5428158943710693],\n",
       " [-0.37580310659639343, -0.5289673924682454],\n",
       " [-0.3654534859313209, -0.5155634851203305],\n",
       " [-0.3556914724291275, -0.5025810904103367],\n",
       " [-0.34646974929283425, -0.48999914013095397],\n",
       " [-0.33774603318668767, -0.4777983315848341],\n",
       " [-0.32948240454053496, -0.46596091729447053],\n",
       " [-0.3216447444555136, -0.45447052585054487],\n",
       " [-0.3142022585837112, -0.4433120085008169],\n",
       " [-0.30712707243062204, -0.43247130714481846],\n",
       " [-0.30039388566829656, -0.421935340229526],\n",
       " [-0.29397967548415493, -0.41169190369399755],\n",
       " [-0.28786344089697036, -0.4017295846281622],\n",
       " [-0.2820259814737466, -0.3920376857234981],\n",
       " [-0.2764497050728871, -0.38260615892450356],\n",
       " [-0.2711184601904371, -0.3734255469573158],\n",
       " [-0.26601738925033025, -0.36448693162904877],\n",
       " [-0.2611327997968593, -0.35578188796879656],\n",
       " [-0.25645205104896585, -0.3473024434268257],\n",
       " [-0.2519634536852739, -0.33904104146854475],\n",
       " [-0.24765618106463103, -0.33099050899931365],\n",
       " [-0.24352019036375055, -0.32314402713893703],\n",
       " [-0.2395461523427632, -0.31549510493386235],\n",
       " [-0.2357253886400878, -0.30803755565314067],\n",
       " [-0.23204981565717034, -0.30076547536308745],\n",
       " [-0.2285118942270326, -0.2936732235168952],\n",
       " [-0.22510458437280112, -0.28675540533049276],\n",
       " [-0.22182130455715, -0.2800068557457699],\n",
       " [-0.21865589490388246, -0.27342262480774576],\n",
       " [-0.21560258394113044, -0.26699796430406647],\n",
       " [-0.21265595847385843, -0.2607283155339433],\n",
       " [-0.20981093624314823, -0.2546092980897757],\n",
       " [-0.20706274107245748, -0.24863669954863568],\n",
       " [-0.20440688023779627, -0.24280646598285419],\n",
       " [-0.20183912383047098, -0.23711469320942613],\n",
       " [-0.19935548590847027, -0.23155761870706457],\n",
       " [-0.196952207256349, -0.22613161413768723],\n",
       " [-0.19462573959414112, -0.22083317841607053],\n",
       " [-0.19237273109384712, -0.2156589312774978],\n",
       " [-0.19019001307777458, -0.21060560729857775],\n",
       " [-0.18807458778678363, -0.2056700503311157],\n",
       " [-0.18602361711856796, -0.20084920831307002],\n",
       " [-0.18403441224672235, -0.1961401284242911],\n",
       " [-0.18210442404069874, -0.19153995255798534],\n",
       " [-0.1802312342150083, -0.18704591308172175],\n",
       " [-0.17841254714332305, -0.182655328864354],\n",
       " [-0.17664618227959522, -0.17836560154750356],\n",
       " [-0.1749300671340483, -0.17417421204227437],\n",
       " [-0.17326223075699182, -0.17007871723367843],\n",
       " [-0.17164079768795143, -0.16607674687686708],\n",
       " [-0.17006398233165418, -0.1621660006707106],\n",
       " [-0.16853008372602457, -0.15834424549556636],\n",
       " [-0.16703748067058205, -0.15460931280324103],\n",
       " [-0.16558462718652847, -0.15095909614820072],\n",
       " [-0.16417004828241424, -0.14739154885002667],\n",
       " [-0.16279233600160836, -0.14390468177796514],\n",
       " [-0.1614501457298989, -0.14049656124918863],\n",
       " [-0.16014219274344502, -0.13716530703308075],\n",
       " [-0.15886724897900875, -0.13390909045448557],\n",
       " [-0.15762414000993885, -0.1307261325894327],\n",
       " [-0.15641174221277335, -0.1276147025473666],\n",
       " [-0.15522898011059144, -0.12457311583437856],\n",
       " [-0.15407482388039032, -0.12159973279236751],\n",
       " [-0.15294828701280197, -0.11869295710944469],\n",
       " [-0.15184842411340915, -0.11585123439725278],\n",
       " [-0.15077432883577863, -0.1130730508311932],\n",
       " [-0.1497251319371117, -0.11035693184985175],\n",
       " [-0.14869999944812487, -0.10770144091018301],\n",
       " [-0.14769813094942333, -0.1051051782952619],\n",
       " [-0.14671875794722453, -0.1025667799716376],\n",
       " [-0.14576114234183102, -0.10008491649353332],\n",
       " [-0.14482457498274914, -0.09765829195132675],\n",
       " [-0.14390837430480488, -0.09528564296192153],\n",
       " [-0.1430118850400248, -0.09296573769878207],\n",
       " [-0.14213447700043322, -0.0906973749595524],\n",
       " [-0.1412755439272675, -0.08847938326931762],\n",
       " [-0.14043450240243638, -0.08631062001769237],\n",
       " [-0.13961079081834366, -0.08418997062803812],\n",
       " [-0.13880386840247183, -0.08211634775721889],\n",
       " [-0.13801321429337363, -0.0800886905244047],\n",
       " [-0.13723832666495, -0.07810596376752484],\n",
       " [-0.13647872189610885, -0.07616715732605843],\n",
       " [-0.13573393378309517, -0.07427128534892935],\n",
       " [-0.13500351279196732, -0.07241738562634609],\n",
       " [-0.1342870253488623, -0.07060451894449575],\n",
       " [-0.13358405316584973, -0.06883176846206492],\n",
       " [-0.1328941926003189, -0.06709823910761929],\n",
       " [-0.13221705404597747, -0.0654030569969291],\n",
       " [-0.13155226135366482, -0.06374536886937858],\n",
       " [-0.1308994512802985, -0.06212434154264575],\n",
       " [-0.13025827296437936, -0.06053916138488317],\n",
       " [-0.1296283874265805, -0.05898903380367225],\n",
       " [-0.12900946709403782, -0.057473182751062495],\n",
       " [-0.12840119534704564, -0.05599085024404349],\n",
       " [-0.12780326608694162, -0.054541295899831616],\n",
       " [-0.12721538332403906, -0.05312379648538519],\n",
       " [-0.1266372607845347, -0.05173764548059184],\n",
       " [-0.12606862153538434, -0.050382152654599804],\n",
       " [-0.12550919762620003, -0.04905664365479117],\n",
       " [-0.1249587297472774, -0.04776045960791989],\n",
       " [-0.12441696690291602, -0.04649295673296043],\n",
       " [-0.12388366609924362, -0.045253505965234794],\n",
       " [-0.1233585920458014, -0.04404149259140632],\n",
       " [-0.12284151687019099, -0.04285631589494775],\n",
       " [-0.12233221984512306, -0.0416973888117094],\n",
       " [-0.12183048712724594, -0.040564137595230504],\n",
       " [-0.1213361115071674, -0.039456001491452654],\n",
       " [-0.12084889217011609, -0.038372432422510004],\n",
       " [-0.1203686344667197, -0.03731289467928492],\n",
       " [-0.11989514969340653, -0.036276864622431564],\n",
       " [-0.11942825488196354, -0.035263830391582845],\n",
       " [-0.11896777259781056, -0.034273291622468165],\n",
       " [-0.11851353074657334, -0.03330475917168112],\n",
       " [-0.11806536238856137, -0.03235775484884711],\n",
       " [-0.11762310556077737, -0.031431811155951325],\n",
       " [-0.11718660310610506, -0.030526471033597062],\n",
       " [-0.11675570250934093, -0.029641287613974165],\n",
       " [-0.11633025573975324, -0.028775823980325688],\n",
       " [-0.11591011909986779, -0.027929652932709645],\n",
       " [-0.1154951530801962, -0.02710235675986054],\n",
       " [-0.11508522221963662, -0.02629352701696297],\n",
       " [-0.11468019497129095, -0.025502764309156847],\n",
       " [-0.1142799435734558, -0.024729678080600642],\n",
       " [-0.11388434392555649, -0.023973886408925584],\n",
       " [-0.11349327546880526, -0.023235015804919983],\n",
       " [-0.11310662107137587, -0.02251270101728882],\n",
       " [-0.11272426691789685, -0.021806584842339365],\n",
       " [-0.11234610240307581, -0.021116317938449033],\n",
       " [-0.11197202002927642, -0.020441558645176803],\n",
       " [-0.11160191530787798, -0.019781972806884533],\n",
       " [-0.11123568666425658, -0.019137233600739108],\n",
       " [-0.11087323534623383, -0.018507021368970953],\n",
       " [-0.11051446533584719, -0.017891023455268707],\n",
       " [-0.11015928326430245, -0.01728893404519397],\n",
       " [-0.109807598329976, -0.016700454010503994],\n",
       " [-0.10945932221934031, -0.016125290757273966],\n",
       " [-0.10911436903069252, -0.01556315807771414],\n",
       " [-0.10877265520057111, -0.015013776005580534],\n",
       " [-0.10843409943275151, -0.014476870675081277],\n",
       " [-0.1080986226297161, -0.013952174183183815],\n",
       " [-0.1077661478264993, -0.013439424455231302],\n",
       " [-0.1074366001268125, -0.012938365113779418],\n",
       " [-0.1071099066413584, -0.012448745350567657],\n",
       " [-0.10678599642824815, -0.011970319801541894],\n",
       " [-0.10646480043543853, -0.011502848424847579],\n",
       " [-0.10614625144511036, -0.011046096381715472],\n",
       " [-0.10583028401991267, -0.01059983392016419],\n",
       " [-0.1055168344510004, -0.010163836261446199],\n",
       " [-0.10520584070779694, -0.009737883489166078],\n",
       " [-0.1048972423894154, -0.00932176044100207],\n",
       " [-0.1045909806776757, -0.008915256602963953],\n",
       " [-0.10428699829165705, -0.008518166006122315],\n",
       " [-0.10398523944372841, -0.008130287125746188],\n",
       " [-0.10368564979700123, -0.007751422782787874],\n",
       " [-0.10338817642415213, -0.0073813800476555886],\n",
       " [-0.1030927677675644, -0.007019970146216244],\n",
       " [-0.10279937360074025, -0.00666700836797238],\n",
       " [-0.10250794499093697, -0.006322313976358841],\n",
       " [-0.10221843426298287, -0.005985710121106365],\n",
       " [-0.1019307949642299, -0.005657023752620723],\n",
       " [-0.10164498183060243, -0.005336085538327511],\n",
       " [-0.10136095075370277, -0.005022729780934091],\n",
       " [-0.10107865874893575, -0.004716794338561518],\n",
       " [-0.10079806392461645, -0.004418120546700611],\n",
       " [-0.10051912545202626, -0.004126553141947578],\n",
       " [-0.10024180353638422, -0.003841940187475822],\n",
       " [-0.0999660593887015, -0.0035641330002017645],\n",
       " [-0.0996918551984886, -0.0032929860796036214],\n",
       " [-0.09941915410728572, -0.0030283570381532204],\n",
       " [-0.09914792018298806, -0.002770106533321991],\n",
       " [-0.09887811839493889, -0.002518098201123308],\n",
       " [-0.09860971458976435, -0.0022721985911543707],\n",
       " [-0.09834267546792476, -0.0020322771031017874],\n",
       " [-0.09807696856095852, -0.0017982059246759601],\n",
       " [-0.09781256220939522, -0.001569859970940296],\n",
       " [-0.09754942554131575, -0.001347116825002154],\n",
       " [-0.09728752845153801, -0.0011298566800332969],\n",
       " [-0.09702684158140744, -0.0009179622825884545],\n",
       " [-0.09676733629917256, -0.0007113188771914147],\n",
       " [-0.09650898468092653, -0.0005098141521588432],\n",
       " [-0.09625175949209609, -0.00031333818663280006],\n",
       " [-0.09599563416946037, -0.00012178339879365786],\n",
       " [-0.09574058280368228, 6.495550477415266e-05],\n",
       " [-0.09548658012233627, 0.00024698157859044445],\n",
       " [-0.09523360147341646, 0.0004243956866878224],\n",
       " [-0.0949816228093099, 0.0005972965499460162],\n",
       " [-0.09473062067122028, 0.0007657807923768963],\n",
       " [-0.09448057217402786, 0.0009299429863844509],\n",
       " [-0.09423145499157204, 0.0010898756970233957],\n",
       " [-0.09398324734234316, 0.0012456695252795011],\n",
       " [-0.09373592797557115, 0.0013974131503941521],\n",
       " [-0.09348947615769836, 0.0015451933712550983],\n",
       " [-0.09324387165922511, 0.0016890951468748134],\n",
       " [-0.09299909474191626, 0.001829201635977358],\n",
       " [-0.09275512614635784, 0.001965594235714129],\n",
       " [-0.0925119470798532, 0.0020983526195283817],\n",
       " [-0.0922695392046483, 0.0022275547741879252],\n",
       " [-0.09202788462647613, 0.0023532770360049295],\n",
       " [-0.09178696588341091, 0.002475594126261311],\n",
       " [-0.0915467659350226, 0.002594579185857734],\n",
       " [-0.09130726815182283, 0.0027103038092038153],\n",
       " [-0.09106845630499362, 0.0028228380773667166],\n",
       " [-0.09083031455639055, 0.002932250590494873],\n",
       " [-0.09059282744881225, 0.003038608499533233],\n",
       " [-0.09035597989652837, 0.0031419775372459736],\n",
       " [-0.09011975717605863, 0.003242422048562291],\n",
       " [-0.0898841449171955, 0.0033400050202604804],\n",
       " [-0.08964912909426344, 0.003434788110005179],\n",
       " [-0.08941469601760797, 0.0035268316747522734],\n",
       " [-0.08918083232530791, 0.0036161947985356526],\n",
       " [-0.08894752497510429, 0.0037029353196496332],\n",
       " [-0.08871476123653999, 0.0037871098572405766],\n",
       " [-0.08848252868330378, 0.003868773837320891],\n",
       " [-0.08825081518577323, 0.0039479815182183065],\n",
       " [-0.08801960890375075, 0.004024786015473011],\n",
       " [-0.08778889827938734, 0.004099239326194935],\n",
       " [-0.08755867203028873, 0.004171392352893209],\n",
       " [-0.08732891914279896, 0.004241294926789498],\n",
       " [-0.0870996288654562, 0.004308995830626699],\n",
       " [-0.08687079070261634, 0.004374542820984169],\n",
       " [-0.08664239440823934, 0.004437982650110441],\n",
       " [-0.08641442997983417, 0.004499361087284091],\n",
       " [-0.08618688765255779, 0.0045587229397132025],\n",
       " [-0.08595975789346397, 0.004616112072983631],\n",
       " [-0.0857330313958979, 0.004671571431066017],\n",
       " [-0.08550669907403256, 0.004725143055891297],\n",
       " [-0.08528075205754305, 0.004776868106504214],\n",
       " [-0.08505518168641506, 0.004826786877804133],\n",
       " [-0.08482997950588388, 0.004874938818882232],\n",
       " [-0.08460513726150054, 0.0049213625509639605],\n",
       " [-0.08438064689432152, 0.004966095884965428],\n",
       " [-0.08415650053621875, 0.005009175838672203],\n",
       " [-0.0839326905053067, 0.005050638653548811],\n",
       " [-0.08370920930148355, 0.005090519811187027],\n",
       " [-0.08348604960208314, 0.005128854049400878],\n",
       " [-0.08326320425763503, 0.00516567537797609],\n",
       " [-0.0830406662877297, 0.005201017094081542],\n",
       " [-0.08281842887698607, 0.005234911797350112],\n",
       " [-0.08259648537111873, 0.005267391404636158],\n",
       " [-0.08237482927310227, 0.005298487164456663],\n",
       " [-0.08215345423943007, 0.005328229671122985],\n",
       " [-0.08193235407646517, 0.005356648878569928],\n",
       " [-0.08171152273688077, 0.005383774113888754],\n",
       " [-0.08149095431618818, 0.005409634090570575],\n",
       " [-0.0812706430493496, 0.005434256921466425],\n",
       " [-0.08105058330747401, 0.005457670131470193],\n",
       " [-0.08083076959459363, 0.005479900669930425],\n",
       " [-0.08061119654451906, 0.005500974922796902],\n",
       " [-0.08039185891777105, 0.005520918724507745],\n",
       " [-0.08017275159858693, 0.005539757369622686],\n",
       " [-0.07995386959199982, 0.005557515624208006],\n",
       " [-0.07973520802098868, 0.005574217736978537],\n",
       " [-0.07951676212369749, 0.005589887450201973],\n",
       " [-0.07929852725072167, 0.005604548010370667],\n",
       " [-0.07908049886246031, 0.005618222178645923],\n",
       " [-0.07886267252653215, 0.005630932241079716],\n",
       " [-0.078645043915254, 0.005642700018618663],\n",
       " [-0.07842760880317999, 0.005653546876894934],\n",
       " [-0.07821036306469993, 0.005663493735808728],\n",
       " [-0.07799330267169553, 0.0056725610789067965],\n",
       " [-0.07777642369125286, 0.005680768962561435],\n",
       " [-0.07755972228342972, 0.0056881370249542325],\n",
       " [-0.07734319469907656, 0.005694684494868802],\n",
       " [-0.07712683727770958, 0.005700430200296612],\n",
       " [-0.07691064644543462, 0.005705392576859925],\n",
       " [-0.07669461871292083, 0.00570958967605582],\n",
       " [-0.07647875067342261, 0.00571303917332511],\n",
       " [-0.07626303900084877, 0.005715758375949958],\n",
       " [-0.07604748044787775, 0.005717764230783858],\n",
       " [-0.07583207184411764, 0.005719073331817588],\n",
       " [-0.07561681009431008, 0.005719701927584664],\n",
       " [-0.07540169217657676, 0.00571966592840975],\n",
       " [-0.07518671514070766, 0.005718980913503379],\n",
       " [-0.07497187610648981, 0.00571766213790631],\n",
       " [-0.07475717226207582, 0.0057157245392867205],\n",
       " [-0.07454260086239088, 0.00571318274459342],\n",
       " [-0.07432815922757768, 0.005710051076568146],\n",
       " [-0.07411384474147796, 0.005706343560119986],\n",
       " [-0.07389965485015003, 0.005702073928564864],\n",
       " [-0.07368558706042128, 0.005697255629732993],\n",
       " [-0.0734716389384749, 0.005691901831947112],\n",
       " [-0.07325780810846991, 0.005686025429874282],\n",
       " [-0.07304409225119368, 0.0056796390502539445],\n",
       " [-0.07283048910274628, 0.0056727550575048835],\n",
       " [-0.07261699645325571, 0.00566538555921369],\n",
       " [-0.07240361214562342, 0.0056575424115072595],\n",
       " [-0.0721903340742993, 0.005649237224311792],\n",
       " [-0.07197716018408541, 0.005640481366500734],\n",
       " [-0.07176408846896791, 0.005631285970934029],\n",
       " [-0.07155111697097628, 0.005621661939390985],\n",
       " [-0.07133824377906936, 0.005611619947399052],\n",
       " [-0.07112546702804748, 0.00560117044896071],\n",
       " [-0.07091278489749007, 0.005590323681180653],\n",
       " [-0.0707001956107182, 0.005579089668795394],\n",
       " [-0.07048769743378129, 0.005567478228607362],\n",
       " [-0.07027528867446763, 0.005555498973825541],\n",
       " [-0.07006296768133792, 0.005543161318314625],\n",
       " [-0.06985073284278154, 0.005530474480754656],\n",
       " [-0.06963858258609466, 0.005517447488713036],\n",
       " [-0.06942651537658008, 0.005504089182630782],\n",
       " [-0.06921452971666787, 0.005490408219724857],\n",
       " [-0.06900262414505667, 0.0054764130778083495],\n",
       " [-0.06879079723587493, 0.0054621120590302615],\n",
       " [-0.0685790475978617, 0.0054475132935366015],\n",
       " [-0.06836737387356648, 0.005432624743054465],\n",
       " [-0.06815577473856776, 0.005417454204400736],\n",
       " [-0.0679442489007097, 0.005402009312917009],\n",
       " [-0.06773279509935651, 0.005386297545832301],\n",
       " [-0.06752141210466424, 0.005370326225555083],\n",
       " [-0.06731009871686951, 0.00535410252289614],\n",
       " [-0.06709885376559464, 0.005337633460223711],\n",
       " [-0.0668876761091691, 0.00532092591455237],\n",
       " [-0.06667656463396648, 0.005303986620567025],\n",
       " [-0.0664655182537571, 0.005286822173583435],\n",
       " [-0.06625453590907543, 0.005269439032446577],\n",
       " [-0.06604361656660226, 0.005251843522368184],\n",
       " [-0.06583275921856124, 0.0052340418377047485],\n",
       " [-0.06562196288212929, 0.005216040044677235],\n",
       " [-0.06541122659886077, 0.005197844084033761],\n",
       " [-0.06520054943412491, 0.005179459773656436],\n",
       " [-0.06498993047655632, 0.005160892811113542],\n",
       " [-0.06477936883751821, 0.005142148776158224],\n",
       " [-0.06456886365057796, 0.005123233133174804],\n",
       " [-0.0643584140709949, 0.005104151233573846],\n",
       " [-0.06414801927521993, 0.005084908318137042],\n",
       " [-0.06393767846040666, 0.005065509519312981],\n",
       " [-0.06372739084393383, 0.005045959863464848],\n",
       " [-0.0635171556629389, 0.005026264273071061],\n",
       " [-0.06330697217386222, 0.005006427568879841],\n",
       " [-0.06309683965200187, 0.0049864544720186876],\n",
       " [-0.06288675739107874, 0.0049663496060597225],\n",
       " [-0.06267672470281162, 0.0049461174990418156],\n",
       " [-0.06246674091650209, 0.00492576258545042],\n",
       " [-0.062256805378629064, 0.0049052892081559996],\n",
       " [-0.06204691745245258, 0.004884701620311929],\n",
       " [-0.06183707651762683, 0.00486400398721272],\n",
       " [-0.06162728196982199, 0.004843200388113402],\n",
       " [-0.061417533220354925, 0.004822294818010893],\n",
       " [-0.06120782969582823, 0.004801291189388143],\n",
       " [-0.06099817083777772, 0.0047801933339218505],\n",
       " [-0.060788556102327994, 0.004759005004154508],\n",
       " [-0.06057898495985592, 0.004737729875131535],\n",
       " [-0.06036945689466189, 0.004716371546004234],\n",
       " [-0.06015997140464862, 0.004694933541599278],\n",
       " [-0.05995052800100738, 0.004673419313955455],\n",
       " [-0.05974112620791141, 0.004651832243828338],\n",
       " [-0.059531765562216406, 0.004630175642163563],\n",
       " [-0.05932244561316791, 0.004608452751539385],\n",
       " [-0.05911316592211539, 0.004586666747579143],\n",
       " [-0.05890392606223297, 0.004564820740334271],\n",
       " [-0.05869472561824649, 0.004542917775638486],\n",
       " [-0.05848556418616692, 0.004520960836433741],\n",
       " [-0.05827644137302985, 0.004498952844068551],\n",
       " [-0.05806735679664101, 0.004476896659569263],\n",
       " [-0.057858310085327616, 0.004454795084884846],\n",
       " [-0.057649300877695424, 0.004432650864105748],\n",
       " [-0.057440328822391376, 0.004410466684657374],\n",
       " [-0.05723139357787171, 0.004388245178468715],\n",
       " [-0.05702249481217538, 0.004365988923116646],\n",
       " [-0.056813632202702705, 0.004343700442946404],\n",
       " [-0.05660480543599905, 0.004321382210168756],\n",
       " [-0.056396014207543546, 0.004299036645934327],\n",
       " [-0.0561872582215426, 0.004276666121385589],\n",
       " [-0.05597853719072818, 0.004254272958686964],\n",
       " [-0.05576985083616073, 0.004231859432033499],\n",
       " [-0.055561198887036575, 0.0042094277686385816],\n",
       " [-0.05535258108049982, 0.004186980149701106],\n",
       " [-0.055143997161458465, 0.0041645187113525505],\n",
       " [-0.054935446882404836, 0.0041420455455843585],\n",
       " [-0.05472693000324007, 0.004119562701156061],\n",
       " [-0.05451844629110266, 0.004097072184484531],\n",
       " [-0.05430999552020094, 0.0040745759605147576],\n",
       " [-0.05410157747164937, 0.004052075953572547],\n",
       " [-0.05389319193330864, 0.004029574048199513],\n",
       " [-0.053684838699629374, 0.004007072089970732],\n",
       " [-0.05347651757149948, 0.003984571886295422],\n",
       " [-0.05326822835609497, 0.003962075207201011],\n",
       " [-0.05305997086673417, 0.003939583786100933],\n",
       " [-0.052851744922735366, 0.003917099320546487],\n",
       " [-0.05264355034927762, 0.003894623472963115],\n",
       " [-0.052435386977264804, 0.0038721578713713915],\n",
       " [-0.0522272546431928, 0.0038497041100930738],\n",
       " [-0.052019153189019667, 0.0038272637504425102],\n",
       " [-0.05181108246203886, 0.003804838321403714],\n",
       " [-0.051603042314755286, 0.0037824293202934037],\n",
       " [-0.05139503260476426, 0.003760038213410304],\n",
       " [-0.051187053194633195, 0.0037376664366709934],\n",
       " [-0.05097910395178602, 0.003715315396232578],\n",
       " [-0.05077118474839026, 0.0036929864691024666],\n",
       " [-0.050563295461246674, 0.003670681003735521],\n",
       " [-0.05035543597168144, 0.003648400320618837],\n",
       " [-0.050147606165440825, 0.0036261457128444223],\n",
       " [-0.04993980593258823, 0.003603918446670017],\n",
       " [-0.049732035167403654, 0.0035817197620683083],\n",
       " [-0.04952429376828537, 0.00355955087326478],\n",
       " [-0.04931658163765397, 0.003537412969264433],\n",
       " [-0.0491088986818585, 0.003515307214367612],\n",
       " [-0.04890124481108483, 0.0034932347486751605],\n",
       " [-0.048693619939266054, 0.0034711966885831304],\n",
       " [-0.048486023983995014, 0.0034491941272672614],\n",
       " [-0.04827845686643875, 0.003427228135157447],\n",
       " [-0.04807091851125499, 0.0034052997604023896],\n",
       " [-0.047863408846510476, 0.0033834100293246563],\n",
       " [-0.04765592780360124, 0.0033615599468663276],\n",
       " [-0.04744847531717463, 0.0033397504970254423],\n",
       " [-0.04724105132505317, 0.003317982643283424],\n",
       " [-0.047033655768160154, 0.003296257329023682],\n",
       " [-0.04682628859044695, 0.003274575477941564],\n",
       " [-0.04661894973882194, 0.003252937994445849],\n",
       " [-0.04641163916308114, 0.003231345764051948],\n",
       " [-0.046204356815840356, 0.00320979965376699],\n",
       " [-0.04599710265246891, 0.00318830051246696],\n",
       " [-0.04578987663102492, 0.0031668491712660563],\n",
       " [-0.04558267871219201, 0.0031454464438784246],\n",
       " [-0.0453755088592175, 0.0031240931269724344],\n",
       " [-0.045168367037852014, 0.0031027900005176443],\n",
       " [-0.044961253216290444, 0.0030815378281246137],\n",
       " [-0.0447541673651143, 0.0030603373573777092],\n",
       " [-0.04454710945723535, 0.003039189320161048],\n",
       " [-0.04434007946784059, 0.0030180944329777255],\n",
       " [-0.04413307737433842, 0.0029970533972624594],\n",
       " [-0.04392610315630611, 0.0029760668996877972],\n",
       " [-0.04371915679543842, 0.0029551356124640103],\n",
       " [-0.04351223827549743, 0.0029342601936328126],\n",
       " [-0.04330534758226352, 0.0029134412873550296],\n",
       " [-0.043098484703487434, 0.0028926795241923423],\n",
       " [-0.042891649628843474, 0.00287197552138323],\n",
       " [-0.04268484234988379, 0.002851329883113235],\n",
       " [-0.04247806285999364, 0.002830743200779659],\n",
       " [-0.042271311154347777, 0.0028102160532508173],\n",
       " [-0.04206458722986772, 0.0027897490071199546],\n",
       " [-0.04185789108518012, 0.0027693426169539386],\n",
       " [-0.041651222720575976, 0.002748997425536836],\n",
       " [-0.04144458213797085, 0.0027287139641084795],\n",
       " [-0.041237969340865994, 0.00270849275259813],\n",
       " [-0.04103138433431032, 0.0026883342998533315],\n",
       " [-0.040824827124863274, 0.0026682391038640625],\n",
       " [-0.04061829772055857, 0.0026482076519822807],\n",
       " [-0.04041179613086872, 0.002628240421136954],\n",
       " [-0.040205322366670404, 0.0026083378780446726],\n",
       " [-0.03999887644021064, 0.0025885004794159367],\n",
       " [-0.03979245836507368, 0.002568728672157203],\n",
       " [-0.03958606815614873, 0.002549022893568781],\n",
       " [-0.03937970582959835, 0.0025293835715386706],\n",
       " [-0.039173371402827624, 0.0025098111247324113],\n",
       " [-0.038967064894454, 0.0024903059627790405],\n",
       " [-0.03876078632427785, 0.0024708684864532316],\n",
       " [-0.03855453571325369, 0.0024514990878536933],\n",
       " [-0.03834831308346204, 0.0024321981505779104],\n",
       " [-0.03814211845808196, 0.002412966049893297],\n",
       " [-0.03793595186136421, 0.002393803152904838],\n",
       " [-0.03772981331860501, 0.002374709818719296],\n",
       " [-0.037523702856120396, 0.002355686398606046],\n",
       " [-0.03731762050122119, 0.0023367332361546134],\n",
       " [-0.03711156628218853, 0.0023178506674289842],\n",
       " [-0.036905540228249926, 0.00229903902111875],\n",
       " [-0.03669954236955594, 0.0022802986186871545],\n",
       " [-0.03649357273715732, 0.002261629774516108],\n",
       " [-0.03628763136298271, 0.0022430327960482298],\n",
       " [-0.036081718279816835, 0.00222450798392598],\n",
       " [-0.035875833521279224, 0.0022060556321279417],\n",
       " [-0.03566997712180339, 0.002187676028102314],\n",
       " [-0.03546414911661649, 0.0021693694528976673],\n",
       " [-0.03525834954171945, 0.002151136181291026],\n",
       " [-0.03505257843386757, 0.002132976481913327],\n",
       " [-0.03484683583055153, 0.002114890617372309],\n",
       " [-0.034641121769978876, 0.002096878844372891],\n",
       " [-0.03443543629105588, 0.0020789414138350833],\n",
       " [-0.03422977943336986, 0.002061078571009489],\n",
       " [-0.03402415123717189, 0.0020432905555904423],\n",
       " [-0.033818551743359876, 0.0020255776018268325],\n",
       " [-0.03361298099346207, 0.002007939938630662],\n",
       " [-0.033407439029620914, 0.0019903777896833857],\n",
       " [-0.0332019258945773, 0.001972891373540075],\n",
       " [-0.03299644163165514, 0.0019554809037314533],\n",
       " [-0.03279098628474632, 0.0019381465888638487],\n",
       " [-0.03258555989829599, 0.0019208886327171002],\n",
       " [-0.03238016251728821, 0.0019037072343404669],\n",
       " [-0.03217479418723187, 0.0018866025881465775],\n",
       " [-0.03196945495414699, 0.0018695748840034604],\n",
       " [-0.03176414486455132, 0.0018526243073246958],\n",
       " [-0.0315588639654472, 0.001835751039157726],\n",
       " [-0.03135361230430878, 0.0018189552562703634],\n",
       " [-0.031148389929069514, 0.001802237131235534],\n",
       " [-0.03094319688810991, 0.0017855968325142905],\n",
       " [-0.030738033230245605, 0.0017690345245371315],\n",
       " [-0.030532899004715678, 0.0017525503677836625],\n",
       " [-0.030327794261171243, 0.0017361445188606326],\n",
       " [-0.0301227190496643, 0.0017198171305783786],\n",
       " [-0.02991767342063685, 0.0017035683520257112],\n",
       " [-0.029712657424910242, 0.0016873983286432746],\n",
       " [-0.02950767111367477, 0.0016713072022954106],\n",
       " [-0.02930271453847951, 0.0016552951113405583],\n",
       " [-0.029097787751222393, 0.0016393621907002194],\n",
       " [-0.02889289080414048, 0.0016235085719265188],\n",
       " [-0.0286880237498005, 0.0016077343832683881],\n",
       " [-0.02848318664108956, 0.0015920397497364027],\n",
       " [-0.0282783795312061, 0.0015764247931662975],\n",
       " [-0.02807360247365103, 0.0015608896322811903],\n",
       " [-0.0278688555222191, 0.0015454343827525383],\n",
       " [-0.02766413873099041, 0.0015300591572598539],\n",
       " [-0.027459452154322182, 0.0015147640655492065],\n",
       " [-0.02725479584684068, 0.0014995492144905325],\n",
       " [-0.027050169863433303, 0.001484414708133781],\n",
       " [-0.026845574259240893, 0.0014693606477639174],\n",
       " [-0.026641009089650197, 0.0014543871319548075],\n",
       " [-0.02643647441028649, 0.0014394942566220079],\n",
       " [-0.026231970277006397, 0.0014246821150744823],\n",
       " [-0.02602749674589085, 0.0014099507980652676],\n",
       " [-0.025823053873238213, 0.0013953003938411094],\n",
       " [-0.02561864171555757, 0.0013807309881910905],\n",
       " [-0.025414260329562153, 0.0013662426644942707],\n",
       " [-0.025209909772162937, 0.0013518355037663605],\n",
       " [-0.025005590100462362, 0.0013375095847054453],\n",
       " [-0.024801301371748203, 0.0013232649837367832],\n",
       " [-0.024597043643487585, 0.001309101775056693],\n",
       " [-0.024392816973321126, 0.001295020030675552],\n",
       " [-0.024188621419057216, 0.0012810198204599198],\n",
       " [-0.023984457038666432, 0.001267101212173811],\n",
       " [-0.023780323890276057, 0.0012532642715191275],\n",
       " [-0.02357622203216475, 0.0012395090621752736],\n",
       " [-0.02337215152275733, 0.0012258356458379666],\n",
       " [-0.02316811242061966, 0.0012122440822572619],\n",
       " [-0.022964104784453657, 0.0011987344292748062],\n",
       " [-0.022760128673092437, 0.0011853067428603374],\n",
       " [-0.022556184145495525, 0.0011719610771474451],\n",
       " [-0.022352271260744214, 0.0011586974844686063],\n",
       " [-0.022148390078037008, 0.001145516015389512],\n",
       " [-0.021944540656685163, 0.0011324167187426995],\n",
       " [-0.02174072305610835, 0.0011193996416605037],\n",
       " [-0.02153693733583039, 0.0011064648296073417],\n",
       " [-0.021333183555475106, 0.0010936123264113447],\n",
       " [-0.021129461774762253, 0.0010808421742953497],\n",
       " [-0.020925772053503554, 0.0010681544139072654],\n",
       " [-0.02072211445159881, 0.001055549084349824],\n",
       " [-0.020518489029032104, 0.0010430262232097307],\n",
       " [-0.02031489584586809, 0.0010305858665862263],\n",
       " [-0.020111334962248373, 0.0010182280491190712],\n",
       " [-0.019907806438387948, 0.0010059528040159648],\n",
       " [-0.019704310334571744, 0.000993760163079412],\n",
       " [-0.019500846711151234, 0.000981650156733046],\n",
       " [-0.019297415628541113, 0.0009696228140474214],\n",
       " [-0.019094017147216064, 0.0009576781627652863],\n",
       " [-0.018890651327707585, 0.0009458162293263442],\n",
       " [-0.018687318230600897, 0.0009340370388915177],\n",
       " [-0.01848401791653191, 0.0009223406153667223],\n",
       " [-0.018280750446184272, 0.0009107269814261613],\n",
       " [-0.018077515880286454, 0.0008991961585351514],\n",
       " [-0.01787431427960894, 0.0008877481669724885],\n",
       " [-0.017671145704961443, 0.0008763830258523634],\n",
       " [-0.01746801021719021, 0.0008651007531458357],\n",
       " [-0.017264907877175367, 0.0008539013657018762],\n",
       " [-0.01706183874582833, 0.0008427848792679857],\n",
       " [-0.016858802884089277, 0.000831751308510399],\n",
       " [-0.016655800352924674, 0.0008208006670338826],\n",
       " [-0.016452831213324845, 0.0008099329674011346],\n",
       " [-0.016249895526301617, 0.0007991482211517951],\n",
       " [-0.016046993352885997, 0.0007884464388210735],\n",
       " [-0.0158441247541259, 0.0007778276299580033],\n",
       " [-0.015641289791083954, 0.0007672918031433293],\n",
       " [-0.015438488524835313, 0.0007568389660070361],\n",
       " [-0.015235721016465547, 0.0007464691252455248],\n",
       " [-0.015032987327068571, 0.0007361822866384458],\n",
       " [-0.014830287517744614, 0.000725978455065193],\n",
       " [-0.014627621649598235, 0.0007158576345210685],\n",
       " [-0.014424989783736386, 0.0007058198281331231],\n",
       " [-0.01422239198126651, 0.0006958650381756786],\n",
       " [-0.014019828303294688, 0.000685993266085541],\n",
       " [-0.013817298810923822, 0.0006762045124769074],\n",
       " [-0.013614803565251856, 0.0006664987771559764],\n",
       " [-0.013412342627370037, 0.0006568760591352647],\n",
       " [-0.013209916058361217, 0.0006473363566476388],\n",
       " [-0.013007523919298186, 0.000637879667160065],\n",
       " [-0.012805166271242044, 0.000628505987387086],\n",
       " [-0.012602843175240607, 0.0006192153133040274],\n",
       " [-0.012400554692326846, 0.000610007640159941],\n",
       " [-0.012198300883517366, 0.0006008829624902899],\n",
       " [-0.011996081809810905, 0.0005918412741293805],\n",
       " [-0.011793897532186879, 0.0005828825682225464],\n",
       " [-0.011591748111603949, 0.00057400683723809],\n",
       " [-0.01138963360899862, 0.0005652140729789857],\n",
       " [-0.011187554085283873, 0.0005565042665943505],\n",
       " [-0.01098550960134782, 0.0005478774085906866],\n",
       " [-0.010783500218052395, 0.0005393334888428989],\n",
       " [-0.010581525996232067, 0.0005308724966050956],\n",
       " [-0.01037958699669258, 0.0005224944205211724],\n",
       " [-0.010177683280209729, 0.0005141992486351872],\n",
       " [-0.009975814907528139, 0.0005059869684015287],\n",
       " [-0.009773981939360103, 0.0004978575666948834],\n",
       " [-0.00957218443638441, 0.0004898110298200045],\n",
       " [-0.009370422459245223, 0.00048184734352128757],\n",
       " [-0.009168696068550966, 0.00047396649299215636],\n",
       " [-0.008967005324873241, 0.0004661684628842625],\n",
       " [-0.008765350288745763, 0.0004584532373165033],\n",
       " [-0.008563731020663322, 0.00045082079988386156],\n",
       " [-0.008362147581080758, 0.00044327113366606977],\n",
       " [-0.00816060003041197, 0.00043580422123610385],\n",
       " [-0.007959088429028932, 0.00042842004466850896],\n",
       " [-0.007757612837260735, 0.0004211185855475608],\n",
       " [-0.007556173315392652, 0.00041389982497526623],\n",
       " [-0.007354769923665217, 0.00040676374357920595],\n",
       " [-0.007153402722273321, 0.00039971032152022283],\n",
       " [-0.006952071771365333, 0.00039273953849995895],\n",
       " [-0.0067507771310422356, 0.00038585137376824405],\n",
       " [-0.006549518861356775, 0.00037904580613033924],\n",
       " [-0.00634829702231263, 0.0003723228139540378],\n",
       " [-0.006147111673863602, 0.0003656823751766271],\n",
       " [-0.0059459628759128145, 0.0003591244673117136],\n",
       " [-0.00574485068831193, 0.000352649067455914],\n",
       " [-0.005543775170860388, 0.00034625615229541567],\n",
       " [-0.005342736383304649, 0.0003399456981124083],\n",
       " [-0.005141734385337462, 0.00033371768079138987],\n",
       " [-0.00494076923659714, 0.0003275720758253493],\n",
       " [-0.004739840996666853, 0.0003215088583218284],\n",
       " [-0.0045389497250739345, 0.00031552800300886554],\n",
       " [-0.0043380954812892005, 0.0003096294842408232],\n",
       " [-0.004137278324726283, 0.00030381327600410233],\n",
       " [-0.003936498314740972, 0.00029807935192274526],\n",
       " [-0.00373575551063058, 0.00029242768526392953],\n",
       " [-0.0035350499716333052, 0.00028685824894335505],\n",
       " [-0.0033343817569276195, 0.00028137101553052683],\n",
       " [-0.0031337509256316592, 0.00027596595725393495],\n",
       " [-0.0029331575368026328, 0.0002706430460061342],\n",
       " [-0.002732601649436236, 0.0002654022533487256],\n",
       " [-0.0025320833224660813, 0.0002602435505172411],\n",
       " [-0.0023316026147631353, 0.0002551669084259345],\n",
       " [-0.0021311595851351674, 0.0002501722976724792],\n",
       " [-0.0019307542923262108, 0.00024525968854257593],\n",
       " [-0.0017303867950160298, 0.00024042905101447114],\n",
       " [-0.0015300571518195995, 0.00023568035476338904],\n",
       " [-0.0013297654212865945, 0.00023101356916587794],\n",
       " [-0.0011295116619008869, 0.00022642866330407338],\n",
       " [-0.000929295932080053, 0.00022192560596987932],\n",
       " [-0.0007291182901748896, 0.00021750436566906933],\n",
       " [-0.0005289787944689382, 0.0002131649106253093],\n",
       " [-0.0003288775031780187, 0.00020890720878410305],\n",
       " [-0.00012881447444977086, 0.00020473122781666293],\n",
       " [7.121023363679615e-05, 0.00020063693512370622],\n",
       " [0.0002711965630717459, 0.0001966242978391796],\n",
       " [0.0004711444559146492, 0.00019269328283391245],\n",
       " [0.000671053854295011, 0.000188843856719201],\n",
       " [0.0008709247004126901, 0.00018507598585032424],\n",
       " [0.0010707569365383108, 0.00018138963632999353],\n",
       " [0.0012705505050136683, 0.00017778477401173657],\n",
       " [0.0014703053482521264, 0.00017426136450321764],\n",
       " [0.0016700214087390093, 0.00017081937316949526],\n",
       " [0.0018696986290319853, 0.0001674587651362183],\n",
       " [0.002069336951761446, 0.000164179505292762],\n",
       " [0.002268936319630877, 0.00016098155829530526],\n",
       " [0.0024684966754172236, 0.00015786488856984996],\n",
       " [0.0026680179619712504, 0.00015482946031518388],\n",
       " [0.0028675001222178945, 0.00015187523750578822],\n",
       " [0.003066943099156613, 0.00014900218389469084],\n",
       " [0.0032663468358617247, 0.00014621026301626632],\n",
       " [0.0034657112754827466, 0.00014349943818898388],\n",
       " [0.003665036361244725, 0.00014086967251810437],\n",
       " [0.00386432203644856, 0.0001383209288983272],\n",
       " [0.004063568244471327, 0.0001358531700163883],\n",
       " [0.004262774928766589, 0.00013346635835361005],\n",
       " [0.004461942032864712, 0.00013116045618840426],\n",
       " [0.004661069500373164, 0.00012893542559872908],\n",
       " [0.0048601572749768195, 0.00012679122846450067],\n",
       " [0.005059205300438254, 0.00012472782646996087],\n",
       " [0.005258213520598035, 0.0001227451811060013],\n",
       " [0.005457181879375008, 0.00012084325367244527],\n",
       " [0.00565611032076658, 0.00011902200528028794],\n",
       " [0.005854998788848997, 0.00011728139685389582],\n",
       " [0.006053847227777616, 0.00011562138913316637],\n",
       " [0.006252655581787177, 0.00011404194267564847],\n",
       " [0.006451423795192067, 0.00011254301785862458],\n",
       " [0.0066501518123865825, 0.0001111245748811555],\n",
       " [0.0068488395778451856, 0.00010978657376608816],\n",
       " [0.00704748703612276, 0.00010852897436202757],\n",
       " [0.007246094131854858, 0.0001073517363452734],\n",
       " [0.007444660809757951, 0.00010625481922172196],\n",
       " [0.00764318701462967, 0.00010523818232873444],\n",
       " [0.007841672691349043, 0.00010430178483697182],\n",
       " [0.008040117784876736, 0.00010344558575219738],\n",
       " [0.008238522240255283, 0.00010266954391704726],\n",
       " [0.008436886002609311, 0.00010197361801276993],\n",
       " [0.008635209017145777, 0.00010135776656093503],\n",
       " [0.008833491229154179, 0.00010082194792511225],\n",
       " [0.009031732584006785, 0.00010036612031252089],\n",
       " [0.009229933027158842, 9.999024177565067e-05],\n",
       " [0.009428092504148796, 9.969427021385441e-05],\n",
       " [0.009626210960598503, 9.947816337491306e-05],\n",
       " [0.009824288342213432, 9.934187885657373e-05],\n",
       " [0.010022324594782873, 9.928537410806127e-05],\n",
       " [0.010220319664180142, 9.930860643156384e-05],\n",
       " [0.010418273496362776, 9.941153298369311e-05],\n",
       " [0.010616186037372735, 9.959411077691955e-05],\n",
       " [0.010814057233336592, 9.985629668098332e-05],\n",
       " [0.011011887030465729, 0.00010019804742428124],\n",
       " [0.011209675375056525, 0.0001006193195952304],\n",
       " [0.01140742221349054, 0.00010112006964360876],\n",
       " [0.011605127492234708, 0.00010170025388187333],\n",
       " [0.011802791157841507, 0.0001023598284864563],\n",
       " [0.012000413156949151, 0.00010309874949903961],\n",
       " [0.012197993436281761, 0.00010391697282780838],\n",
       " [0.012395531942649543, 0.00010481445424868367],\n",
       " [0.012593028622948959, 0.0001057911494065349],\n",
       " [0.0127904834241629, 0.00010684701381637245],\n",
       " [0.012987896293360853, 0.00010798200286452071],\n",
       " [0.013185267177699073, 0.00010919607180977223],\n",
       " [0.013382596024420742, 0.00011048917578452296],\n",
       " [0.013579882780856135, 0.00011186126979588933],\n",
       " [0.01377712739442278, 0.0001133123087268074],\n",
       " [0.013974329812625615, 0.00011484224733711434],\n",
       " [0.014171489983057152, 0.0001164510402646128],\n",
       " [0.014368607853397624, 0.00011813864202611833],\n",
       " [0.014565683371415141, 0.00011990500701849036],\n",
       " [0.014762716484965846, 0.00012175008951964695],\n",
       " [0.014959707141994058, 0.00012367384368956367],\n",
       " [0.015156655290532424, 0.00012567622357125696],\n",
       " [0.015353560878702066, 0.0001277571830917523],\n",
       " [0.015550423854712723, 0.00012991667606303747],\n",
       " [0.015747244166862892, 0.00013215465618300108],\n",
       " [0.015944021763539977, 0.000134471077036357],\n",
       " [0.016140756593220423, 0.00013686589209555458],\n",
       " [0.016337448604469854, 0.00013933905472167526],\n",
       " [0.016534097745943208, 0.00014189051816531563],\n",
       " [0.016730703966384878, 0.0001445202355674574],\n",
       " [0.016927267214628842, 0.00014722815996032437],\n",
       " [0.017123787439598793, 0.00015001424426822687],\n",
       " [0.017320264590308273, 0.00015287844130839356],\n",
       " [0.017516698615860797, 0.00015582070379179143],\n",
       " [0.017713089465449992, 0.0001588409843239336],\n",
       " [0.01790943708835971, 0.00016193923540567563],\n",
       " [0.018105741433964154, 0.0001651154094340004],\n",
       " [0.018302002451728014, 0.0001683694587027917],\n",
       " [0.018498220091206573, 0.00017170133540359703],\n",
       " [0.018694394302045843, 0.00017511099162637945],\n",
       " [0.018890525033982673, 0.00017859837936025914],\n",
       " [0.019086612236844866, 0.00018216345049424447],\n",
       " [0.01928265586055131, 0.0001858061568179531],\n",
       " [0.01947865585511208, 0.00018952645002232312],\n",
       " [0.019674612170628554, 0.0001933242817003145],\n",
       " [0.019870524757293534, 0.0001971996033476011],\n",
       " [0.02006639356539135, 0.0002011523663632534],\n",
       " [0.020262218545297975, 0.00020518252205041192],\n",
       " [0.020457999647481132, 0.00020929002161695204],\n",
       " [0.020653736822500404, 0.00021347481617613976],\n",
       " [0.020849430021007337, 0.00021773685674727914],\n",
       " [0.021045079193745556, 0.00022207609425635118],\n",
       " [0.02124068429155086, 0.0002264924795366446],\n",
       " [0.021436245265351327, 0.0002309859633293784],\n",
       " [0.021631762066167425, 0.00023555649628431678],\n",
       " [0.021827234645112104, 0.00024020402896037603],\n",
       " [0.022022662953390903, 0.00024492851182622414],\n",
       " [0.022218046942302044, 0.0002497298952608728],\n",
       " [0.02241338656323653, 0.0002546081295542621],\n",
       " [0.022608681767678256, 0.0002595631649078383],\n",
       " [0.022803932507204083, 0.0002645949514351245],\n",
       " [0.022999138733483953, 0.0002697034391622844],\n",
       " [0.023194300398280975, 0.00027488857802867954],\n",
       " [0.023389417453451515, 0.0002801503178874199],\n",
       " [0.023584489850945297, 0.00028548860850590796],\n",
       " [0.023779517542805488, 0.00029090339956637664],\n",
       " [0.023974500481168788, 0.00029639464066642096],\n",
       " [0.02416943861826552, 0.0003019622813195238],\n",
       " [0.024364331906419727, 0.0003076062709555754],\n",
       " [0.024559180298049245, 0.0003133265589213875],\n",
       " [0.0247539837456658, 0.0003191230944812016],\n",
       " [0.024948742201875092, 0.0003249958268171913],\n",
       " [0.025143455619376875, 0.00033094470502995993],\n",
       " [0.025338123950965047, 0.00033696967813903224],\n",
       " [0.025532747149527732, 0.000343070695083341],\n",
       " [0.025727325168047353, 0.0003492477047217085],\n",
       " [0.025921857959600725, 0.0003555006558333232],\n",
       " [0.026116345477359134, 0.00036182949711821105],\n",
       " [0.026310787674588405, 0.00036823417719770236],\n",
       " [0.026505184504648994, 0.0003747146446148938],\n",
       " [0.02669953592099606, 0.00038127084783510563],\n",
       " [0.026893841877179542, 0.0003879027352463347],\n",
       " [0.02708810232684423, 0.0003946102551597027],\n",
       " [0.02728231722372985, 0.0004013933558099003],\n",
       " [0.02747648652167113, 0.00040825198535562684],\n",
       " [0.027670610174597883, 0.0004151860918800258],\n",
       " [0.027864688136535063, 0.00042219562339111644],\n",
       " [0.028058720361602858, 0.0004292805278222213],\n",
       " [0.02825270680401674, 0.0004364407530323894],\n",
       " [0.028446647418087556, 0.0004436762468068163],\n",
       " [0.028640542158221576, 0.0004509869568572597],\n",
       " [0.02883439097892058, 0.0004583728308224519],\n",
       " [0.029028193834781918, 0.00046583381626850794],\n",
       " [0.02922195068049857, 0.0004733698606893312],\n",
       " [0.02941566147085923, 0.0004809809115070144],\n",
       " [0.02960932616074835, 0.0004886669160722379],\n",
       " [0.029802944705146224, 0.0004964278216646647],\n",
       " [0.029996517059129035, 0.0005042635754933315],\n",
       " [0.030190043177868938, 0.0005121741246970372],\n",
       " [0.0303835230166341, 0.0005201594163447283],\n",
       " [0.03057695653078878, 0.0005282193974358804],\n",
       " [0.030770343675793378, 0.0005363540149008778],\n",
       " [0.030963684407204504, 0.000544563215601389],\n",
       " [0.03115697868067503, 0.0005528469463307404],\n",
       " [0.03135022645195415, 0.0005612051538142863],\n",
       " [0.03154342767688744, 0.0005696377847097768],\n",
       " [0.03173658231141692, 0.0005781447856077218],\n",
       " [0.0319296903115811, 0.0005867261030317542],\n",
       " [0.032122751633515044, 0.0005953816834389886],\n",
       " [0.03231576623345042, 0.0006041114732203787],\n",
       " [0.03250873406771556, 0.0006129154187010714],\n",
       " [0.0327016550927355, 0.0006217934661407591],\n",
       " [0.03289452926503206, 0.0006307455617340286],\n",
       " [0.033087356541223856, 0.000639771651610709],\n",
       " [0.033280136878026396, 0.0006488716818362162],\n",
       " [0.0334728702322521, 0.0006580455984118952],\n",
       " [0.033665556560810356, 0.0006672933472753611],\n",
       " [0.03385819582070757, 0.0006766148743008363],\n",
       " [0.03405078796904724, 0.0006860101252994872],\n",
       " [0.03424333296302994, 0.0006954790460197577],\n",
       " [0.034435830759953455, 0.0007050215821477013],\n",
       " [0.034628281317212746, 0.0007146376793073103],\n",
       " [0.03482068459230005, 0.0007243272830608446],\n",
       " [0.03501304054280489, 0.0007340903389091566],\n",
       " [0.03520534912641414, 0.0007439267922920154],\n",
       " [0.03539761030091208, 0.0007538365885884293],\n",
       " [0.035589824024180414, 0.0007638196731169655],\n",
       " [0.035781990254198315, 0.0007738759911360688],\n",
       " [0.03597410894904248, 0.0007840054878443782],\n",
       " [0.03616618006688717, 0.0007942081083810422],\n",
       " [0.036358203566004235, 0.0008044837978260315],\n",
       " [0.03655017940476317, 0.000814832501200451],\n",
       " [0.03674210754163115, 0.0008252541634668494],\n",
       " [0.03693398793517307, 0.0008357487295295282],\n",
       " [0.03712582054405157, 0.0008463161442348479],\n",
       " [0.0373176053270271, 0.0008569563523715333],\n",
       " [0.037509342242957905, 0.0008676692986709779],\n",
       " [0.037701031250800134, 0.0008784549278075453],\n",
       " [0.037892672309607814, 0.0008893131843988705],\n",
       " [0.03808426537853291, 0.0009002440130061594],\n",
       " [0.038275810416825366, 0.0009112473581344867],\n",
       " [0.03846730738383311, 0.0009223231642330921],\n",
       " [0.03865875623900212, 0.0009334713756956763],\n",
       " [0.038850156941876435, 0.0009446919368606945],\n",
       " [0.03904150945209819, 0.0009559847920116492],\n",
       " [0.039232813729407644, 0.0009673498853773816],\n",
       " [0.03942406973364323, 0.0009787871611323619],\n",
       " [0.03961527742474155, 0.0009902965633969778],\n",
       " [0.03980643676273745, 0.001001878036237823],\n",
       " [0.039997547707763995, 0.001013531523667983],\n",
       " [0.04018861022005254, 0.0010252569696473203],\n",
       " [0.040379624259932724, 0.0010370543180827601],\n",
       " [0.04057058978783253, 0.001048923512828572],\n",
       " [0.04076150676427829, 0.0010608644976866522],\n",
       " [0.04095237514989469, 0.0010728772164068053],\n",
       " [0.041143194905404856, 0.0010849616126870235],\n",
       " [0.04133396599163031, 0.0010971176301737657],\n",
       " [0.041524688369491046, 0.0011093452124622354],\n",
       " [0.0417153620000055, 0.0011216443030966576],\n",
       " [0.04190598684429063, 0.0011340148455705546],\n",
       " [0.04209656286356189, 0.0011464567833270208],\n",
       " [0.042287090019133285, 0.0011589700597589966],\n",
       " [0.04247756827241736, 0.0011715546182095424],\n",
       " [0.042667997584925246, 0.001184210401972109],\n",
       " [0.04285837791826667, 0.0011969373542908106],\n",
       " [0.043048709234149954, 0.0012097354183606937],\n",
       " [0.043238991494382074, 0.0012226045373280076],\n",
       " [0.04342922466086865, 0.0012355446542904724],\n",
       " [0.04361940869561395, 0.001248555712297547],\n",
       " [0.04380954356072093, 0.0012616376543506962],\n",
       " [0.04399962921839124, 0.0012747904234036564],\n",
       " [0.04418966563092526, 0.0012880139623627014],\n",
       " [0.04437965276072206, 0.001301308214086907],\n",
       " [0.044569590570279476, 0.0013146731213884142],\n",
       " [0.04475947902219408, 0.0013281086270326928],\n",
       " [0.04494931807916121, 0.0013416146737388036],\n",
       " [0.04513910770397498, 0.0013551912041796597],\n",
       " [0.045328847859528294, 0.0013688381609822877],\n",
       " [0.04551853850881284, 0.0013825554867280872],\n",
       " [0.04570817961491914, 0.001396343123953091],\n",
       " [0.04589777114103649, 0.0014102010151482234],\n",
       " [0.04608731305045305, 0.0014241291027595581],\n",
       " [0.046276805306555785, 0.0014381273291885761],\n",
       " [0.046466247872830525, 0.001452195636792422],\n",
       " [0.04665564071286193, 0.0014663339678841602],\n",
       " [0.04684498379033351, 0.0014805422647330303],\n",
       " [0.04703427706902765, 0.0014948204695647018],\n",
       " [0.0472235205128256, 0.001509168524561529],\n",
       " [0.04741271408570747, 0.0015235863718628035],\n",
       " [0.04760185775175225, 0.0015380739535650082],\n",
       " [0.0477909514751378, 0.0015526312117220692],\n",
       " [0.047979995220140875, 0.0015672580883456073],\n",
       " [0.0481689889511371, 0.00158195452540519],\n",
       " [0.048357932632601, 0.0015967204648285817],\n",
       " [0.048546826229105965, 0.0016115558485019937],\n",
       " [0.04873566970532429, 0.001626460618270334],\n",
       " [0.04892446302602714, 0.0016414347159374564],\n",
       " [0.04911320615608459, 0.0016564780832664092],\n",
       " [0.04930189906046558, 0.0016715906619796824],\n",
       " [0.049490541704237945, 0.0016867723937594554],\n",
       " [0.0496791340525684, 0.0017020232202478447],\n",
       " [0.04986767607072254, 0.001717343083047149],\n",
       " [0.05005616772406483, 0.0017327319237200964],\n",
       " [0.05024460897805861, 0.0017481896837900886],\n",
       " [0.05043299979826609, 0.001763716304741447],\n",
       " [0.05062134015034835, 0.001779311728019656],\n",
       " [0.05080963000006532, 0.0017949758950316084],\n",
       " [0.05099786931327576, 0.001810708747145847],\n",
       " [0.05118605805593732, 0.0018265102256928092],\n",
       " [0.05137419619410644, 0.0018423802719650688],\n",
       " [0.051562283693938435, 0.0018583188272175782],\n",
       " [0.051750320521687404, 0.0018743258326679104],\n",
       " [0.05193830664370628, 0.0018904012294964998],\n",
       " [0.05212624202644679, 0.001906544958846883],\n",
       " [0.052314126636459464, 0.0019227569618259395],\n",
       " [0.0525019604403936, 0.001939037179504131],\n",
       " [0.052689743404997276, 0.0019553855529157414],\n",
       " [0.052877475497117334, 0.0019718020230591157],\n",
       " [0.05306515668369936, 0.001988286530896898],\n",
       " [0.05325278693178768, 0.0020048390173562714],\n",
       " [0.05344036620852533, 0.0020214594233291935],\n",
       " [0.05362789448115407, 0.0020381476896726355],\n",
       " [0.05381537171701434, 0.002054903757208819],\n",
       " [0.05400279788354527, 0.002071727566725451],\n",
       " [0.05419017294828465, 0.002088619058975963],\n",
       " [0.05437749687886891, 0.0021055781746797436],\n",
       " [0.05456476964303314, 0.0021226048545223766],\n",
       " [0.05475199120861101, 0.0021396990391558744],\n",
       " [0.05493916154353481, 0.0021568606691989133],\n",
       " [0.05512628061583539, 0.0021740896852370673],\n",
       " [0.05531334839364218, 0.0021913860278230425],\n",
       " [0.05550036484518314, 0.0022087496374769105],\n",
       " [0.05568732993878476, 0.002226180454686341],\n",
       " [0.05587424364287202, 0.0022436784199068357],\n",
       " [0.05606110592596839, 0.0022612434735619596],\n",
       " [0.056247916756695805, 0.0022788755560435732],\n",
       " [0.056434676103774624, 0.0022965746077120656],\n",
       " [0.05662138393602363, 0.0023143405688965833],\n",
       " [0.056808040222359996, 0.0023321733798952636],\n",
       " [0.05699464493179927, 0.0023500729809754635],\n",
       " [0.05718119803345533, 0.002368039312373992],\n",
       " [0.05736769949654041, 0.002386072314297337],\n",
       " [0.057554149290365, 0.0024041719269218974],\n",
       " [0.05774054738433789, 0.002422338090394212],\n",
       " [0.057926893747966106, 0.002440570744831187],\n",
       " [0.05811318835085488, 0.0024588698303203266],\n",
       " [0.058299431162707666, 0.0024772352869199587],\n",
       " [0.058485622153326054, 0.0024956670546594653],\n",
       " [0.05867176129260978, 0.0025141650735395083],\n",
       " [0.058857848550556695, 0.0025327292835322576],\n",
       " [0.05904388389726273, 0.0025513596245816178],\n",
       " [0.05922986730292185, 0.002570056036603454],\n",
       " [0.05941579873782606, 0.0025888184594858197],\n",
       " [0.05960167817236534, 0.0026076468330891805],\n",
       " [0.05978750557702764, 0.002626541097246641],\n",
       " [0.05997328092239882, 0.0026455011917641703],\n",
       " [0.06015900417916265, 0.002664527056420826],\n",
       " [0.06034467531810076, 0.00268361863096898],\n",
       " [0.06053029431009261, 0.00270277585513454],\n",
       " [0.06071586112611545, 0.002721998668617178],\n",
       " [0.060901375737244294, 0.0027412870110905493],\n",
       " [0.06108683811465189, 0.0027606408222025183],\n",
       " [0.061272248229608674, 0.0027800600415753816],\n",
       " [0.06145760605348274, 0.0027995446088060895],\n",
       " [0.0616429115577398, 0.002819094463466469],\n",
       " [0.06182816471394316, 0.0028387095451034463],\n",
       " [0.062013365493753664, 0.002858389793239267],\n",
       " [0.062198513868929675, 0.0028781351473717194],\n",
       " [0.06238360981132702, 0.0028979455469743537],\n",
       " [0.06256865329289897, 0.0029178209314967046],\n",
       " [0.06275364428569619, 0.0029377612403645105],\n",
       " [0.06293858276186669, 0.0029577664129799342],\n",
       " [0.0631234686936558, 0.0029778363887217824],\n",
       " [0.06330830205340614, 0.0029979711069457256],\n",
       " [0.06349308281355755, 0.0030181705069845174],\n",
       " [0.06367781094664707, 0.0030384345281482127],\n",
       " [0.0638624864253089, 0.003058763109724387],\n",
       " [0.06404710922227433, 0.0030791561909783547],\n",
       " [0.06423167931037174, 0.0030996137111533864],\n",
       " [0.06441619666252653, 0.0031201356094709273],\n",
       " [0.06460066125176106, 0.0031407218251308148],\n",
       " [0.06478507305119464, 0.003161372297311494],\n",
       " [0.06496943203404348, 0.0031820869651702365],\n",
       " [0.06515373817362063, 0.003202865767843356],\n",
       " [0.06533799144333595, 0.003223708644446423],\n",
       " [0.06552219181669604, 0.003244615534074483],\n",
       " [0.06570633926730421, 0.0032655863758022717],\n",
       " [0.06589043376886045, 0.0032866211086844278],\n",
       " ...]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = Variable(),Variable()\n",
    "f= 100.0*(y - x**2)**2 + (1 - x)**2.0\n",
    "a=gradient_descent(f, {x: -1,y:-1},return_history=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_contour(f, init_val_dict, plot_range=[-10,10],method = 'gradient_descent'):\n",
    "    if method == 'gradient_descent':\n",
    "        a=gradient_descent(f, init_val_dict,return_history=True)\n",
    "    elif method =='newton':\n",
    "        a=newton(f, init_val_dict,return_history=True)\n",
    "    #first plot the contour\n",
    "    xx=np.linspace(plot_range[0],plot_range[1],100)\n",
    "    yy=np.linspace(plot_range[0],plot_range[1],100)\n",
    "    xg,yg = np.meshgrid(xx,yy)\n",
    "    z=np.zeros(shape=(len(xg.ravel()),))\n",
    "    for i,val in enumerate(xg.ravel()):\n",
    "        vals = yg.ravel()\n",
    "        z[i]=f.evaluation_at({x:val,y:vals[i]})\n",
    "    z2 = z.reshape(xg.shape)\n",
    "    plt.contourf(xg,yg,z2,alpha=0.8, cmap=\"BuGn\")\n",
    "    #plot the steps\n",
    "    f_gd = []\n",
    "    x_gd =[]\n",
    "    y_gd =[]\n",
    "    for l in a:\n",
    "        x_gd.append(l[0])\n",
    "        y_gd.append(l[0])\n",
    "        #f_gd.append(f.evaluation_at({x:l[0],y:l[1]}))\n",
    "    plt.plot(x_gd,y_gd,'.',alpha=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEVHBsLATERUMCzsRUcH8P4JqWGWwjv37AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1f67b940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = Variable(),Variable()\n",
    "f= 100.0*(y - x**2)**2 + (1 - x)**2.0\n",
    "plot_contour(f, {x:-2,y:-1}, plot_range=[-3,3],method = 'gradient_descent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.5, -7.0], [-0.5, -7.0]]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1ed57b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = Variable(),Variable()\n",
    "f= exp(-(x*x*y*y+x*x+y*y-8*x-8*y)/2.)\n",
    "plot_range=[-1,8]\n",
    "a=gradient_descent(f, {x: -0.5,y:-7},return_history=True)\n",
    "xx=np.linspace(plot_range[0],plot_range[1],100)\n",
    "yy=np.linspace(plot_range[0],plot_range[1],100)\n",
    "xg,yg = np.meshgrid(xx,yy)\n",
    "z=np.zeros(shape=(len(xg.ravel()),))\n",
    "for i,val in enumerate(xg.ravel()):\n",
    "    vals = yg.ravel()\n",
    "    z[i]=f.evaluation_at({x:val,y:vals[i]})\n",
    "z2 = z.reshape(xg.shape)\n",
    "plt.contourf(xg,yg,z2,alpha=0.8, cmap=\"BuGn\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-2, -2],\n",
       " [-1.997502081598668, 3.9900083263946717],\n",
       " [0.9962640215968228, -7.970093479914039],\n",
       " [0.9962661046310918, 0.99254615123247],\n",
       " [0.9999999999967593, 0.9999860580189168],\n",
       " [0.999999999999991, 0.999999999999982]]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ting/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:278: RuntimeWarning: overflow encountered in power\n",
      "/Users/ting/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:203: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{<__main__.Variable at 0x113ba0278>: nan,\n",
       " <__main__.Variable at 0x113ba06d8>: nan}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f= 100.0*(y - x**2)**2 + (1 - x)**2.0\n",
    "gradient_descent(f, {x:0,y:1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  0.],\n",
       "       [ 0.,  2.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.hessian_at({x: 2,y:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -2.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.solve(f.hessian_at({x: 2,y:2}),-f.gradient_at({x: 2,y:2}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00502513, -1.        ])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = Variable(), Variable()\n",
    "f=100.0*(y - x**2)**2 + (1 - x)**2.0\n",
    "f_grad=f.gradient_at({x: 0.0, y: 1.0})\n",
    "f_hess=f.hessian_at({x: 0.0, y: 1.0})\n",
    "np.linalg.solve(f_hess, -f_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-398.,    0.],\n",
       "       [   0.,  200.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = Variable(), Variable()\n",
    "f=100.0*(y - x**2)**2 + (1 - x)**2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict1= {x: 0.0, y: 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([v for k, v in dict1.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00502513,  0.        ])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+np.linalg.solve(f_hess, -f_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.10503618e+231,   3.11109133e+231,   3.45845952e-323])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
