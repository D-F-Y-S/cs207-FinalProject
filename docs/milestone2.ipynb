{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "* [Introduction](#Introduction)\n",
    "* [Background](#Background)\n",
    "* [How to use the package](#How to use the package)\n",
    "    * [Installing autodiff](#Installing-autodiff)\n",
    "    * [Basic Demo](#Basic-Demo)\n",
    "* [Software Organization](#Software-Organization)\n",
    "    * [Directory Structure](#Directory-Structure)\n",
    "    * [Modules](#Modules)\n",
    "    * [Test Automation](Test-Automation)\n",
    "    * [Distribution](Distribution)\n",
    "\n",
    "* [Implementation Details](#Implementation-Details)\n",
    "    * [Core data structures](#Core-data-structures)\n",
    "    * [Core classes](#Core-classes)\n",
    "    * [Important attributes](#Important-attributes)\n",
    "    * [External dependencies](#External-dependencies)\n",
    "    * [Elementary functions](#Elementary-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic differentiation (AD) is a family of techniques for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. Application of AD includes Newtonâ€™s method for solving nonlinear equations, real-parameter optimization, probabilistic inference, and backpropagation in neural networks. AD has been extremely popular because of the booming development in machine learning and deep learning techniques. Our AD sofeware package enable user to calculate derivatives using the forward and reverse mode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mathematical Background**\n",
    "\n",
    "Automatic Differentiation decomposes a complex function into a sequence of operations on elementary functions, evaluates the derivatives at each intermediate stage, repeatedly applies the chain rule to obtain the derivative of the outermost function.\n",
    "We provides explanations for related math concepts below. \n",
    "\n",
    "**Elimentary functions**\n",
    "\n",
    "The class of functions consisting of the polynomials, the exponential functions, the logarithmic functions, the trigonometric functions, the inverse trigonometric functions,and the functions obtained from those listed by the four arithmetic operations and by superposition(i.e. composition),applied by finitely many times.\n",
    "\n",
    "**Chain Rule**\n",
    "+ Used to compute the derivative of a composite function\n",
    "+ Core of automatic differentiation\n",
    "$$ f \\circ g (x) = f(g(x))$$\n",
    "$$\\dfrac{d}{dx}[f(g(x))] = f'(g(x))g'(x)$$\n",
    "\n",
    "**Dual Numbers**\n",
    "+ Used to compute derivative for elementary functions in automatic differentiation\n",
    "+ Replace x and y with $x+x'\\epsilon$ and $y+y'\\epsilon$. x' and y' are real numbers,$\\epsilon$ is an abstract number with the property: $\\epsilon^2=0$\n",
    "+ Carry out operations, the dual part gives us the derivative\n",
    "\n",
    "**Topological Graph**\n",
    "+ Each node represent a variable\n",
    "+ Arrows indicate topological orders(order of operations) and operations themselves.\n",
    "\n",
    "\n",
    "**Forward Mode Autodifferentiation**\n",
    "\n",
    "Follow the topological order and store the values of each variable in the nodes.\n",
    "visit each node in topological order. Let x denote our innermost function. For variable $u_i=g_i(v)$ we already know $\\dfrac{dv}{dx}$, calculate $\\dfrac{du_i}{dx}= \\dfrac{du_i}{dv}\\dfrac{dv}{dx}$\n",
    "\n",
    "\n",
    "**Reverse Mode Autodifferentiation**\n",
    "\n",
    "Has forward computation and backward computation\n",
    "\n",
    "    **Forward Computation**\n",
    "Follow the topological order and store the values of each variable in each nodes.\n",
    "    \n",
    "    \n",
    "    **Backward Computation**\n",
    "let y denote our final output variable and $u_j$, $v_j$ denote the intermediate variables\n",
    "1. Initialize all partial derivative $\\dfrac{dy}{du_j}$ to 0 and dy/dy = 1\n",
    "2. visit each node in reverse topological order. For variable $u_i=g_i(v_1,...,v_n)$ we already know $\\dfrac{dy}{du_i}$, increment $\\dfrac{dy}{dv_j}$ by $\\dfrac{dy}{du_i}\\dfrac{du_i}{dv_j}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## How to use the package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing `autodiff`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to install `autodiff` on command line. We suppose that the user has already installed `pip` and `virtualenv`:\n",
    "1. clone the project repo by `git clone git@github.com:D-Y-F-S/cs207-FinalProject.git`\n",
    "2. `cd` into the local repo and create a virtual environment by `virtualenv env` \n",
    "3. activate the virtual environment by `source env/bin/activate` (use `deactivate` to deactivate the virtual environment later.)\n",
    "4. install the dependencies by `pip install -r requirements.txt`\n",
    "5. install `autodiff` by `pip install -e .`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Basic Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a `Variable`, which represents an independent variable. Let's call it `x`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autodiff.forward as fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = fwd.Variable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core class in `dyfs` is `Expression`, and we can build up `Expression` from `Variable` and other `Expression`. All functions are represented as `Expression`. All `Expression`, including `Variance` which is the most elementary `Expression`, implements the `evaluation_at` method, returns the value of this `Expression`. It also implements the `derivative_at` method, returns the derivative of this `Expression`.\n",
    "\n",
    "Here we create an `Expression` that represents $f(x) = 2x + \\exp(x)$. There is no need to call the `Expression` constructor explicitly, because the `*` operator on `x` is overloaded and will return an `Expression`. The `exp` function also returns an `Expression` representing $\\exp(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = 2*x + fwd.exp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then evaluate $f(x)$'s value and derivative at $x = 0.5$ by calling `evaluation_at` and `derivative_at` on `f`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.648721270700128"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.evaluation_at({x: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.648721270700128"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.derivative_at(x, {x: 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar operations can be carried out on multivariate functions.\n",
    "\n",
    "Here we first create another `Variable` called `y`. Then we create an `Expression` that represents $g(x, y) = \\exp(x-y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = fwd.Variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = fwd.exp(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then evaluate $g(x, y)$'s value at $x = 0.5, y = -0.5$ by calling `evaluation_at` on `g`. We can also evaluate $\\dfrac{\\partial g}{\\partial x}$ and $\\dfrac{\\partial g}{\\partial y}$ by calling `derivative_at` on `g`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.evaluation_at({x: 0.5, y: -0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.derivative_at(x, {x: 0.5, y: -0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.derivative_at(y, {x: 0.5, y: -0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar operations can be carried out on vector functions.\n",
    "\n",
    "Here we create an `VectorFunction` that represents $h(\\begin{bmatrix}x\\\\y\\end{bmatrix}) = \\begin{bmatrix}f(x)\\\\g(x, y)\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not implemented yet\n",
    "# h = fwd.VectorFunction(fun_dict={f: (x), g: (x, y)}, var_list=[x, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then evaluates $h(x)$'s value and derivative (returned as gradient $\\begin{bmatrix}\\dfrac{\\partial f}{\\partial x}\\\\\\dfrac{\\partial g}{\\partial x}\\end{bmatrix}$ or $\\begin{bmatrix}\\dfrac{\\partial f}{\\partial y}\\\\\\dfrac{\\partial g}{\\partial y}\\end{bmatrix}$) at $x = 0.5, y = -0.5$. The `jacobian_at` function returns the Jacobian ($\\begin{bmatrix}\\dfrac{\\partial f}{\\partial x} & \\dfrac{\\partial f}{\\partial y} \\\\ \\dfrac{\\partial g}{\\partial x} & \\dfrac{\\partial g}{\\partial y} \\end{bmatrix}$) of `h` at given position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# not implemented yet\n",
    "# h.evaluation_at({x: 0.5, y: -0.5})\n",
    "# h.derivative_at(x, {x: 0.5, y: -0.5})\n",
    "# h.derivative_at(y, {x: 0.5, y: -0.5})\n",
    "# h.jacobian_at({x: 0.5, y: -0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Software Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of `autodiff`'s project directory is as follows. \n",
    "```\n",
    "autodiff/\n",
    "\n",
    "    __init__.py\n",
    "    forward.py\n",
    "    \n",
    "tests/\n",
    "\n",
    "    test_forward.py\n",
    "    \n",
    "docs/\n",
    "\n",
    "    milestone1.ipynb\n",
    "    milestone2.ipynb\n",
    "    \n",
    ".gitignore\n",
    ".travis.yml\n",
    "LICENSE.txt\n",
    "README.md\n",
    "requirements.txt\n",
    "setup.cfg\n",
    "setup.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source codes lies in the directory `autodiff`, in which the `__init__.py` is there to make `autodiff` a package. Currently all the source codes are in the file `forward.py`. In the future, we may want to break it into multiple files later for better organization.\n",
    "\n",
    "The test suites lies in the directory `tests`. Currently all the test codes are in the file `test_forward.py`. In the future, we may want to break it into multiple files later for better organization.\n",
    "\n",
    "The documents lies in the directory `docs`. `milestone1.ipynb` is the history version of document when submitting milestone 1. `milestone2.ipynb`, which is this file itself, is the document when submitting milestone 2.\n",
    "\n",
    "Other files in the rrot directory includes: `.gitignore`, which specifies the files that should not be tracked by git, `.travis.yml`, which is the configuration file for TravisCI, `LICENSE.txt`, which is the license for this package, `README.md`, which is the README file for this package, `requirements.txt`, which specifies the dependensies of this package, `setup.cfg`, which is the configuration file for installing this package, `setup.py`, which is the script for installing this package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are currently 1 module in `autodiff`, that is `forward`, which implements the forward mode autodifferenciation. The other modules we are planning to add include: `backward`, which implements the backward mode autodifferenciation. `usecase`, which contains some example client codes built on top of `forward` and `backward`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TravisCI` and `Coveralls` are used for test automation. The test suites for each module is included in the `tests` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently `autodiff` has to be manually installed. It will be distributed with `PyPI` in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Implementation Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About how the derivative is evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The centural data structure in `autodiff` are `Expression` and `ElementFunction` (which is the common interface shared by `Add`, `Mul`, `Pow`, `Exp`, `Sin`... We may want to explicitly add an abstract base class in the future). `Expression`'s are composed of one `ElementFunction`  plus one or two sub-`Expression`'s. When evaluating the derivative, `Expression` will pass its sub-`Expression`('s) to the `ElementFunction`'s `derivative_at` method. `ElementFunction`'s `derivative_at` method will then call the `evaluation_at` method and `derivative_at` method os the sub-`Expression`('s) and use the returned value to calculate derivative. It is a mutual recursive process, where the base lies in `Variable` class and `Constant` class, whose `evaluation_at` method and `derivative_at` method return a solid number (rather than continue calling another function).\n",
    "\n",
    "The `evaluation_at` method works similarly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autodiff.forward.Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Expression` represents an expression. It implements the `evaluation_at` and the `derivative_at` methods. The first returns the value of this expression at a certain point. The second returns the derivative (with respect to given variable / expression) of this expression at a certain point. There is not need to contruct an `Expression` explicitly when using `autodiff`.\n",
    "\n",
    "There are 2 subclass of `Expression`, both implements the same interface but have some difference in their implementation of `evaluation_at` and `derivative_at` methods: `Variable`, which represents an independent 'base' variable, and `Constant`, which represents a constant. \n",
    "\n",
    "The interface of `Expression` is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Expression:\n",
    "    \"\"\"\n",
    "    The contructor of Expression. There is no need to call this \n",
    "    constructor explicitly.\n",
    "    ------------------------\n",
    "    Input:\n",
    "        ele_func:  ElementFunction*, the element function \n",
    "                   involved expression\n",
    "        sub_expr1: Expression, the first sub-expression involved \n",
    "                   in this expression\n",
    "        sub_expr2: Expression, the second sub-expression incolved \n",
    "                   in this expression\n",
    "    * Elementfunction is the common interface shared by Add, Mul, \n",
    "      Sub, Pow, Exp, Sin... We may want to explicitly add an \n",
    "      abstract base class in the future\n",
    "    \"\"\"\n",
    "    def __init__(self, ele_func, sub_expr1, sub_expr2=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    The value of this expression at the point specified by val_dict.\n",
    "    ------------------------\n",
    "    Input:\n",
    "        val_dict: dict, a dictionary representing a point (keys are \n",
    "                  Variables and values are numeric)\n",
    "    Output:\n",
    "        numeric, the value of the expression at the point specified \n",
    "        by val_dict\n",
    "    \"\"\"\n",
    "    def evaluation_at(self, val_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    The derivative with respect to certain variable / expression at \n",
    "    the point specified by valdict.\n",
    "    ------------------------\n",
    "    Input:\n",
    "        var:      Expression, the variable / expression to calculate \n",
    "                  derivative with respect to\n",
    "        val_dict: dict, a dictionary representing a point (keys are \n",
    "                Variables and values are numeric)\n",
    "    Output:\n",
    "        numeric, the derivative with respect to certain variable / \n",
    "        expression at the point specified by valdict\n",
    "    \"\"\"\n",
    "    def derivative_at(self, var, val_dict):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autodiff.forward.Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Variable` is a special kind of `Expression`. Its main purpose is to make the client code more readable. Client codes of `autodiff` typically starts with creating `Variable` objects.\n",
    "\n",
    "The interface of `Variable` is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Variable(Expression):\n",
    "    \"\"\"\n",
    "    The contructor of Constant.\n",
    "    \"\"\"\n",
    "    def __init__(self, val):\n",
    "    \n",
    "    \"\"\"\n",
    "    The value of this variable at the point specified by val_dict.\n",
    "    ------------------------\n",
    "    Input:\n",
    "        val_dict: dict, a dictionary representing a point (keys are\n",
    "        Variables and values are numeric)\n",
    "    Output:\n",
    "        numeric, the value of the expression at the point specified \n",
    "        by val_dict\n",
    "    \"\"\"\n",
    "    def evaluation_at(self, val_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    The derivative with respect to certain variable / expression at \n",
    "    the point specified by valdict. The output of this function will \n",
    "    always be either 0.0 (derivative w.r.t. some other variable) or \n",
    "    1.0 (derivative w.r.t. itself).\n",
    "    ------------------------\n",
    "    Input:\n",
    "        var:      Expression, the variable / expression to calculate \n",
    "                  derivative with respect to\n",
    "        val_dict: dict, a dictionary representing a point (keys are \n",
    "                  Variables and values are numeric)\n",
    "    Output:\n",
    "        numeric, the derivative with respect to certain variable / \n",
    "        expression at the point specified by valdict.\n",
    "    \"\"\"\n",
    "    def derivative_at(self, var, val_dict):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autodiff.forward.Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Constant` is a special kind of `Expression` representing a constant. There is not need to contruct an `Expression` explicitly when using `autodiff`.\n",
    "\n",
    "The interface of `Variable` is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Constant(Expression):\n",
    "    \"\"\"\n",
    "    The contructor of Constant. There is no need to call this \n",
    "    constructor explicitly.\n",
    "    ------------------------\n",
    "    Input:\n",
    "        val: numeric, the value of this constant\n",
    "    \"\"\"\n",
    "    def __init__(self, val):\n",
    "    \n",
    "    \"\"\"\n",
    "    The value of this variable at the point. The output of this \n",
    "    function will always be the val passed to the constructor\n",
    "    ------------------------\n",
    "    Input:\n",
    "        val_dict: dict, a dictionary representing a point (keys are \n",
    "                  Variables and values are numeric)\n",
    "    Output:\n",
    "        numeric, the value of the expression at the point specified \n",
    "        by val_dict\n",
    "    \"\"\"\n",
    "    def evaluation_at(self, val_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    The derivative with respect to certain variable / expression at \n",
    "    the point specified by valdict. The output of this function will \n",
    "    always be 0.0.\n",
    "    ------------------------\n",
    "    Input:\n",
    "        var:      Expression, the variable / expression to calculate \n",
    "                  derivative with respect to\n",
    "        val_dict: dict, a dictionary representing a point (keys are \n",
    "                  Variables and values are numeric)\n",
    "    Output:\n",
    "        numeric, the derivative with respect to certain variable / \n",
    "        expression at the point specified by valdict.\n",
    "    \"\"\"\n",
    "    def derivative_at(self, var, val_dict):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autodiff.forward.VectorFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`VectorFunction` represents a vector function. We haven't implemented this class for now.\n",
    "\n",
    "The interface of `VectorFunction` will be as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VFun:\n",
    "    \n",
    "    def __init__(self, fun_dict, var_list):\n",
    "\n",
    "    def evaluation_at(self, val_dict):\n",
    "        \n",
    "    def derivative_at(self, var, val_dict):\n",
    "    \n",
    "    def jacobian_at(self, val_dict):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autodiff.forward.Exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Exp` represents the elementary function $x \\mapsto \\exp(x)$. It implements 2 methods: `evaluation_at` and `derivative_at`. The first returns the value of some exponential expression. The second returns the derivative of some exponential expression. Its methods are called by `Expression` and need not be called by client codes. \n",
    "\n",
    "The interface of `Exp` is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Exp:\n",
    "    \n",
    "    \"\"\"\n",
    "    The value of this exponential expression at the point.\n",
    "    ------------------------\n",
    "    Input:\n",
    "        sub_expr1: Expression, the expression x in x -> exp(x)\n",
    "        val_dict:  dict, a dictionary representing a point (keys are \n",
    "                   Variables and values are numeric)\n",
    "    Output:\n",
    "        numeric, the value of the expression at the point specified \n",
    "        by val_dict\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def evaluation_at(sub_expr1, val_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    The derivative with respect to certain variable / expression at \n",
    "    the point specified by valdict.\n",
    "    ------------------------\n",
    "    Input:\n",
    "        var:      Expression, the variable / expression to calculate \n",
    "                  derivative with respect to\n",
    "        val_dict: dict, a dictionary representing a point (keys are \n",
    "                  Variables and values are numeric)\n",
    "    Output:\n",
    "        numeric, the derivative with respect to certain variable / \n",
    "        expression at the point specified by valdict.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def derivative_at(sub_expr1, var, val_dict):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autodiff.forward.exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`exp` is a free function that act as the constructor for an expression that has `Exp` as `ele_func`.\n",
    "\n",
    "The interface of `exp` is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return the exponential of an expression.\n",
    "------------------------\n",
    "    Input:\n",
    "        expr: Expression, the expression x in x -> exp(x)\n",
    "    Output:\n",
    "        Expression, the exponential of expr\n",
    "\"\"\"\n",
    "def exp(expr):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
