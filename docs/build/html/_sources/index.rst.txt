DFYS AutoDiff Documentation
====================================

.. toctree::
   :maxdepth: 2

   Overview <self>
   Background.ipynb
   Installation
   Software Organization
   Usage
   Implementation
   Featured Application
   Summary
   License


Introduction
--------------
Automatic differentiation (AD_) is a family of techniques for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. Application of AD includes Newtonâ€™s method for solving nonlinear equations, real-parameter optimization, probabilistic inference, and backpropagation in neural networks. AD has been extremely popular because of the booming development in machine learning and deep learning techniques. Our AD sofeware package enable user to calculate derivatives using the forward and reverse mode. 

Our package has feature including support for second order derivatives (including Hssian matrix), rooting finding, optimization(Newton, Gradient Descent, BFGS), and backpropagation.



This project_ is hosted on GitHub.

.. _AD: https://en.wikipedia.org/wiki/Automatic_differentiation

.. _project: https://github.com/D-F-Y-S/cs207-FinalProject


.. Below are comments - just hiding for now
.. Indices and tables
.. ==================

.. * :ref:`genindex`
.. * :ref:`modindex`

.. * :ref:`search`